"""
åº”ç”¨è¾…åŠ©å‡½æ•°æ¨¡å—
åŒ…å«æ•°æ®å¤„ç†ã€æŠ¥å‘Šç”Ÿæˆã€ä¸‹è½½ç­‰åŠŸèƒ½
"""
import os
import gradio as gr
import pandas as pd
from utils.data_process import DataProcessor
from utils import load_config


# ==================== å…¨å±€å˜é‡ ====================
global_model = None
global_processor = None
global_report = None

# æ ·ä¾‹æ•°æ®è·¯å¾„
EXAMPLE_FILES = {
    "ç³–å°¿ç—…åˆ†ç±»æ•°æ®": "../example/Diabetes Classification.csv",
    "ä½“æ£€æ•°æ®": "../example/medical_examination.csv",
}


# ==================== æ ·ä¾‹æ•°æ®é€‰æ‹© ====================

def select_example_data(example_name):
    """é€‰æ‹©æ ·ä¾‹æ•°æ®"""
    if example_name == "è‡ªå®šä¹‰ä¸Šä¼ " or example_name not in EXAMPLE_FILES:
        return gr.File(value=None)
    
    file_path = EXAMPLE_FILES[example_name]
    # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    abs_path = os.path.normpath(os.path.join(base_dir, file_path))
    
    if os.path.exists(abs_path):
        return gr.File(value=abs_path)
    return gr.File(value=None)


# ==================== æ•°æ®åŠ è½½ä¸åˆ†æ ====================

def load_preview_data(file):
    """åŠ è½½æ•°æ®å¹¶é¢„è§ˆ"""
    if file is None:
        return None, "è¯·å…ˆä¸Šä¼ æ–‡ä»¶"
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        info = f"æ•°æ®å½¢çŠ¶: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—\n"
        info += f"ç¼ºå¤±å€¼æ€»æ•°: {df.isnull().sum().sum()}"
        return df.head(20), info
    except Exception as e:
        return None, f"åŠ è½½å¤±è´¥: {str(e)}"


def analyze_data(file):
    """ä¸Šä¼ æ•°æ®åè‡ªåŠ¨åˆ†æï¼ˆä¸æ‰§è¡Œé¢„å¤„ç†ï¼‰"""
    global global_processor, global_report
    
    if file is None:
        return "", "", None, None, None, None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        processor = DataProcessor(df)
        global_processor = processor
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs("output/plots", exist_ok=True)
        
        # ç”Ÿæˆå››å¼ åˆ†æå›¾å¹¶ä¿å­˜
        plot_paths = {}
        
        try:
            missing_fig = processor.plot_missing_matrix()
            missing_fig.savefig("output/plots/missing.png", dpi=100, bbox_inches='tight')
            plot_paths['missing'] = "output/plots/missing.png"
        except:
            missing_fig = None
            plot_paths['missing'] = None
        
        try:
            outlier_fig = processor.plot_boxplot(normalize=True)
            outlier_fig.savefig("output/plots/outlier.png", dpi=100, bbox_inches='tight')
            plot_paths['outlier'] = "output/plots/outlier.png"
        except:
            outlier_fig = None
            plot_paths['outlier'] = None
        
        try:
            dist_fig = processor.plot_distribution()
            dist_fig.savefig("output/plots/distribution.png", dpi=100, bbox_inches='tight')
            plot_paths['distribution'] = "output/plots/distribution.png"
        except:
            dist_fig = None
            plot_paths['distribution'] = None
        
        try:
            corr_fig = processor.plot_correlation_heatmap()
            corr_fig.savefig("output/plots/correlation.png", dpi=100, bbox_inches='tight')
            plot_paths['correlation'] = "output/plots/correlation.png"
        except:
            corr_fig = None
            plot_paths['correlation'] = None
        
        # ç”ŸæˆæŠ¥å‘Šï¼ˆå¸¦å›¾ç‰‡è·¯å¾„ï¼‰
        report = processor.generate_report()
        report['plot_paths'] = plot_paths
        global_report = report
        
        # ç”Ÿæˆå¸¦å›¾ç‰‡çš„ Markdown æŠ¥å‘Š
        md_with_images = generate_markdown_with_images(report, plot_paths)
        report['markdown_with_images'] = md_with_images
        
        return (
            md_with_images,
            report['llm_prompt'],
            missing_fig,
            outlier_fig,
            dist_fig,
            corr_fig
        )
    except Exception as e:
        import traceback
        traceback.print_exc()
        return f"åˆ†æå¤±è´¥: {str(e)}", "", None, None, None, None


def generate_markdown_with_images(report: dict, plot_paths: dict) -> str:
    """ç”Ÿæˆå¸¦å›¾ç‰‡çš„ Markdown æŠ¥å‘Š"""
    md = report['markdown']
    
    # åœ¨æŠ¥å‘Šæœ«å°¾æ·»åŠ å›¾ç‰‡éƒ¨åˆ†
    md += "\n\n## ğŸ“ˆ åˆ†æå›¾è¡¨\n\n"
    
    if plot_paths.get('missing'):
        md += "### ç¼ºå¤±å€¼åˆ†æ\n"
        md += f"![ç¼ºå¤±å€¼åˆ†æ](plots/missing.png)\n\n"
    
    if plot_paths.get('outlier'):
        md += "### å¼‚å¸¸å€¼åˆ†æ\n"
        md += f"![å¼‚å¸¸å€¼åˆ†æ](plots/outlier.png)\n\n"
    
    if plot_paths.get('distribution'):
        md += "### æ•°æ®åˆ†å¸ƒ\n"
        md += f"![æ•°æ®åˆ†å¸ƒ](plots/distribution.png)\n\n"
    
    if plot_paths.get('correlation'):
        md += "### ç›¸å…³æ€§åˆ†æ\n"
        md += f"![ç›¸å…³æ€§åˆ†æ](plots/correlation.png)\n\n"
    
    return md


# ==================== å•ç‹¬åˆ†æå‡½æ•° ====================

def get_missing_info(file):
    """è·å–ç¼ºå¤±å€¼ä¿¡æ¯"""
    if file is None:
        return None, None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        processor = DataProcessor(df)
        missing_info = processor.get_missing_info()
        missing_fig = processor.plot_missing_matrix()
        
        return missing_info, missing_fig
    except Exception as e:
        return None, None


def get_outlier_info(file):
    """è·å–å¼‚å¸¸å€¼ä¿¡æ¯å¹¶ç»˜åˆ¶ç®±çº¿å›¾"""
    if file is None:
        return None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        processor = DataProcessor(df)
        fig = processor.plot_boxplot()
        return fig
    except Exception as e:
        return None


def get_distribution_info(file):
    """è·å–æ•°æ®åˆ†å¸ƒä¿¡æ¯"""
    if file is None:
        return None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        processor = DataProcessor(df)
        fig = processor.plot_distribution()
        return fig
    except Exception as e:
        return None


def get_correlation_info(file):
    """è·å–ç›¸å…³æ€§çƒ­åŠ›å›¾"""
    if file is None:
        return None, None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        processor = DataProcessor(df)
        fig = processor.plot_correlation_heatmap()
        high_corr = processor.get_high_correlation_pairs()
        
        return fig, high_corr
    except Exception as e:
        return None, None


# ==================== æ•°æ®é¢„å¤„ç† ====================

def process_data(file, fill_strategy, outlier_method):
    """æ‰§è¡Œæ•°æ®é¢„å¤„ç†å¹¶é‡æ–°ç”Ÿæˆåˆ†æå›¾è¡¨"""
    global global_processor, global_report
    
    if file is None:
        return None, "è¯·å…ˆä¸Šä¼ æ–‡ä»¶", "", "", None, None, None, None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        # æ‰§è¡Œæ•°æ®å¤„ç†
        processor = DataProcessor(df)
        processor.fill_missing(strategy=fill_strategy)
        processor.handle_outliers(method=outlier_method)
        
        global_processor = processor
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs("output/plots", exist_ok=True)
        
        # ç”¨å¤„ç†åçš„æ•°æ®ç”Ÿæˆåˆ†æå›¾è¡¨
        plot_paths = {}
        
        try:
            missing_fig = processor.plot_missing_matrix()
            missing_fig.savefig("output/plots/missing.png", dpi=100, bbox_inches='tight')
            plot_paths['missing'] = "output/plots/missing.png"
        except:
            missing_fig = None
            plot_paths['missing'] = None
        
        try:
            outlier_fig = processor.plot_boxplot(normalize=True)
            outlier_fig.savefig("output/plots/outlier.png", dpi=100, bbox_inches='tight')
            plot_paths['outlier'] = "output/plots/outlier.png"
        except:
            outlier_fig = None
            plot_paths['outlier'] = None
        
        try:
            dist_fig = processor.plot_distribution()
            dist_fig.savefig("output/plots/distribution.png", dpi=100, bbox_inches='tight')
            plot_paths['distribution'] = "output/plots/distribution.png"
        except:
            dist_fig = None
            plot_paths['distribution'] = None
        
        try:
            corr_fig = processor.plot_correlation_heatmap()
            corr_fig.savefig("output/plots/correlation.png", dpi=100, bbox_inches='tight')
            plot_paths['correlation'] = "output/plots/correlation.png"
        except:
            corr_fig = None
            plot_paths['correlation'] = None
        
        # ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š
        report = processor.generate_report()
        report['plot_paths'] = plot_paths
        
        # ç”Ÿæˆå¸¦å›¾ç‰‡çš„ Markdown æŠ¥å‘Š
        md_with_images = generate_markdown_with_images(report, plot_paths)
        report['markdown_with_images'] = md_with_images
        global_report = report
        
        # ç®€çŸ­å¤„ç†æ—¥å¿—
        log = processor.get_processing_log()
        brief_report = f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼\n\nå¤„ç†æ­¥éª¤:\n"
        brief_report += "\n".join([f"â€¢ {item}" for item in log])
        brief_report += f"\n\nå¤„ç†åæ•°æ®: {processor.get_data().shape[0]} è¡Œ Ã— {processor.get_data().shape[1]} åˆ—"
        
        return (
            processor.get_data().head(20), 
            brief_report, 
            md_with_images,
            report['llm_prompt'],
            missing_fig,
            outlier_fig,
            dist_fig,
            corr_fig
        )
    except Exception as e:
        import traceback
        traceback.print_exc()
        return None, f"å¤„ç†å¤±è´¥: {str(e)}", "", "", None, None, None, None


# ==================== ä¸‹è½½åŠŸèƒ½ ====================

def download_report():
    """ä¸‹è½½åˆ†ææŠ¥å‘Šï¼ˆåŒ…å«å›¾ç‰‡çš„ zip åŒ…ï¼‰"""
    global global_report
    import zipfile
    
    if global_report is None:
        return gr.File(visible=False)
    
    os.makedirs("output", exist_ok=True)
    
    # å†™å…¥å¸¦å›¾ç‰‡è·¯å¾„çš„ Markdown
    md_content = global_report.get('markdown_with_images', global_report['markdown'])
    md_path = "output/data_analysis_report.md"
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(md_content)
    
    # åˆ›å»º zip åŒ…ï¼ˆåŒ…å«æŠ¥å‘Šå’Œå›¾ç‰‡ï¼‰
    zip_path = "output/data_analysis_report.zip"
    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        # æ·»åŠ  Markdown æŠ¥å‘Š
        zipf.write(md_path, "data_analysis_report.md")
        
        # æ·»åŠ å›¾ç‰‡
        plots_dir = "output/plots"
        if os.path.exists(plots_dir):
            for img_file in os.listdir(plots_dir):
                if img_file.endswith('.png'):
                    zipf.write(os.path.join(plots_dir, img_file), f"plots/{img_file}")
    
    return gr.File(value=zip_path, visible=True)


def download_chat_history(history):
    """ä¸‹è½½å¯¹è¯å†å²"""
    import json
    from datetime import datetime
    
    if not history:
        return gr.File(visible=False)
    
    os.makedirs("output", exist_ok=True)
    
    # ç”Ÿæˆ Markdown æ ¼å¼çš„å¯¹è¯è®°å½•
    md_content = "# ğŸ’¬ AI å¯¹è¯è®°å½•\n\n"
    md_content += f"**å¯¼å‡ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
    md_content += "---\n\n"
    
    for msg in history:
        role = msg.get('role', 'unknown')
        content = msg.get('content', '')
        
        if role == 'user':
            md_content += f"### ğŸ‘¤ ç”¨æˆ·\n\n{content}\n\n"
        elif role == 'assistant':
            md_content += f"### ğŸ¤– AI åŠ©æ‰‹\n\n{content}\n\n"
        
        md_content += "---\n\n"
    
    # ä¿å­˜ Markdown æ–‡ä»¶
    output_path = "output/chat_history.md"
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(md_content)
    
    # åŒæ—¶ä¿å­˜ JSON æ ¼å¼ï¼ˆä¾¿äºç¨‹åºè¯»å–ï¼‰
    json_path = "output/chat_history.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(history, f, ensure_ascii=False, indent=2)
    
    return gr.File(value=output_path, visible=True)


def download_processed_data():
    """ä¸‹è½½å¤„ç†åçš„æ•°æ®"""
    global global_processor
    
    if global_processor is None:
        return gr.File(visible=False)
    
    os.makedirs("output", exist_ok=True)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    output_path = "output/processed_data.csv"
    global_processor.get_data().to_csv(output_path, index=False)
    return gr.File(value=output_path, visible=True)


def send_to_training(encode_strategy: str = 'auto'):
    """
    å°†å¤„ç†åçš„æ•°æ®ä¼ é€’åˆ°æ¨¡å‹è®­ç»ƒæ¨¡å—
    
    Args:
        encode_strategy: åˆ†ç±»å˜é‡ç¼–ç ç­–ç•¥ (auto/label/onehot)
    """
    global global_processor
    
    if global_processor is None:
        return gr.File(value=None), "âš ï¸ è¯·å…ˆæ‰§è¡Œæ•°æ®é¢„å¤„ç†"
    
    os.makedirs("output", exist_ok=True)
    
    # å¤åˆ¶ä¸€ä»½å¤„ç†å™¨ç”¨äºç¼–ç ï¼ˆä¸å½±å“åŸæ•°æ®ï¼‰
    from utils.data_process import DataProcessor
    df_copy = global_processor.get_data().copy()
    encoder = DataProcessor(df_copy)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦ç¼–ç çš„åˆ†ç±»åˆ—
    cat_cols = encoder.get_categorical_columns()
    encode_info = ""
    
    if cat_cols:
        # æ‰§è¡Œåˆ†ç±»å˜é‡ç¼–ç 
        encoder.encode_categorical(strategy=encode_strategy)
        encode_log = encoder.get_processing_log()
        encode_info = f"\nğŸ“Š ç¼–ç ä¿¡æ¯: {encode_log[-1] if encode_log else 'æ— '}"
    
    # ä¿å­˜ç¼–ç åçš„æ•°æ®
    output_path = "output/processed_data_for_training.csv"
    encoder.get_data().to_csv(output_path, index=False)
    
    # æ•°æ®ä¿¡æ¯
    df = encoder.get_data()
    info = f"âœ… å·²åŠ è½½é¢„å¤„ç†æ•°æ®\n"
    info += f"æ•°æ®å½¢çŠ¶: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—"
    
    if cat_cols:
        info += f"\nåŸåˆ†ç±»åˆ—: {list(cat_cols.keys())}"
        info += encode_info
    else:
        info += "\nï¼ˆæ— éœ€ç¼–ç çš„åˆ†ç±»åˆ—ï¼‰"
    
    return gr.File(value=output_path), info


# ==================== LLM ç›¸å…³ ====================

def prepare_for_llm(llm_prompt):
    """å‡†å¤‡å‘é€ç»™ LLM çš„å†…å®¹ï¼Œå¡«å…¥è¾“å…¥æ¡†ä¾›ç”¨æˆ·ç¡®è®¤"""
    global global_report
    
    if not llm_prompt:
        return "âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®æˆ–æ‰§è¡Œé¢„å¤„ç†ä»¥ç”Ÿæˆåˆ†ææŠ¥å‘Š", None
    
    # å‡†å¤‡å›¾ç‰‡è·¯å¾„ï¼ˆåˆå¹¶æˆä¸€å¼ æ‹¼æ¥å›¾ï¼‰
    image_path = None
    if global_report and global_report.get('plot_paths'):
        # å°è¯•æ‹¼æ¥å››å¼ å›¾ä¸ºä¸€å¼ 
        try:
            from PIL import Image
            
            plot_paths = global_report['plot_paths']
            images = []
            for key in ['missing', 'outlier', 'distribution', 'correlation']:
                path = plot_paths.get(key)
                if path and os.path.exists(path):
                    images.append(Image.open(path))
            
            if images:
                # åˆ›å»º 2x2 æ‹¼æ¥å›¾
                widths = [img.width for img in images]
                heights = [img.height for img in images]
                max_w = max(widths) if widths else 400
                max_h = max(heights) if heights else 300
                
                # åˆ›å»ºç”»å¸ƒ
                combined = Image.new('RGB', (max_w * 2, max_h * 2), 'white')
                
                positions = [(0, 0), (max_w, 0), (0, max_h), (max_w, max_h)]
                for i, img in enumerate(images[:4]):
                    # è°ƒæ•´å›¾ç‰‡å¤§å°
                    img_resized = img.resize((max_w, max_h), Image.Resampling.LANCZOS)
                    combined.paste(img_resized, positions[i])
                
                # ä¿å­˜æ‹¼æ¥å›¾
                os.makedirs("output/plots", exist_ok=True)
                image_path = "output/plots/combined_analysis.png"
                combined.save(image_path)
        except Exception as e:
            print(f"å›¾ç‰‡æ‹¼æ¥å¤±è´¥: {e}")
            # å¦‚æœæ‹¼æ¥å¤±è´¥ï¼Œä½¿ç”¨ç¬¬ä¸€å¼ å›¾
            for key in ['correlation', 'distribution', 'outlier', 'missing']:
                path = global_report.get('plot_paths', {}).get(key)
                if path and os.path.exists(path):
                    image_path = path
                    break
    
    # è¿”å›æ–‡æœ¬å’Œå›¾ç‰‡è·¯å¾„ï¼Œå¡«å…¥è¾“å…¥æ¡†
    text = f"ğŸ“Š æ•°æ®åˆ†æè¯·æ±‚:\n\n{llm_prompt}"
    return text, image_path


def update_provider_info(agent_id):
    """æ›´æ–°æ˜¾ç¤ºçš„æä¾›å•†ä¿¡æ¯"""
    try:
        config = load_config()
        agent_config = config.get('agent_models', {}).get(agent_id, {})
        provider = agent_config.get('provider', config.get('default_provider', 'kimi'))
        model_type = agent_config.get('model', 'default')
        
        # è·å–å®é™…æ¨¡å‹åç§°
        providers = config.get('llm_providers', {})
        model_name = providers.get(provider, {}).get('models', {}).get(model_type, 'unknown')
        
        return f"**å½“å‰æ¨¡å‹**: {provider} / {model_name}"
    except:
        return "**å½“å‰æ¨¡å‹**: é…ç½®åŠ è½½å¤±è´¥"


def user_input_handler(user_message, image, history, img_cache):
    """å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆæ–‡æœ¬+å›¾ç‰‡ï¼‰"""
    if not user_message and not image:
        return "", None, history, img_cache
    
    new_history = list(history)
    
    # æ„å»ºæ˜¾ç¤ºæ–‡æœ¬
    if image:
        text = user_message or "è¯·åˆ†æè¿™å¼ å›¾ç‰‡"
        display_text = f"ğŸ“· [å·²ä¸Šä¼ å›¾ç‰‡]\n{text}"
        img_cache = image  # ç¼“å­˜å›¾ç‰‡è·¯å¾„ä¾› API ä½¿ç”¨
    else:
        display_text = user_message
        img_cache = None
    
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆçº¯æ–‡æœ¬æ ¼å¼ï¼ŒGradio å…¼å®¹ï¼‰
    new_history.append({"role": "user", "content": display_text})
        
    return "", None, new_history, img_cache


# ==================== å¯åŠ¨é…ç½® ====================

def setup_frpc():
    """è‡ªåŠ¨é…ç½® frpcï¼ˆä»é¡¹ç›® bin ç›®å½•å¤åˆ¶åˆ° Gradio ç¼“å­˜ï¼‰"""
    import shutil
    from pathlib import Path
    
    # é¡¹ç›® bin ç›®å½•ä¸­çš„ frpc
    project_root = Path(__file__).parent.parent.parent
    src_frpc = project_root / "bin" / "frpc_linux_amd64_v0.3"
    
    # Gradio ç¼“å­˜ç›®å½•
    gradio_cache = Path.home() / ".cache" / "huggingface" / "gradio" / "frpc"
    dst_frpc = gradio_cache / "frpc_linux_amd64_v0.3"
    
    if src_frpc.exists():
        gradio_cache.mkdir(parents=True, exist_ok=True)
        if not dst_frpc.exists() or dst_frpc.stat().st_size != src_frpc.stat().st_size:
            shutil.copy2(src_frpc, dst_frpc)
            dst_frpc.chmod(0o755)
            print(f"âœ… frpc å·²é…ç½®: {dst_frpc}")
        return True
    return False

