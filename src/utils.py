import pandas as pd
import yaml
import base64
from pathlib import Path
from openai import OpenAI
from typing import Generator


def encode_image_to_base64(image_path: str) -> str:
    """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def get_image_mime_type(image_path: str) -> str:
    """è·å–å›¾ç‰‡MIMEç±»å‹"""
    suffix = Path(image_path).suffix.lower()
    mime_types = {
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".png": "image/png",
        ".gif": "image/gif",
        ".webp": "image/webp"
    }
    return mime_types.get(suffix, "image/jpeg")

def load_data(filepath):
    """
    æ­¤å‡½æ•°ç”¨äºåŠ è½½æ•°æ®é›†ï¼Œæ”¯æŒ xlsx å’Œ csv æ–‡ä»¶ï¼Œä¼šåˆ é™¤æœ‰ç¼ºå¤±å€¼çš„æ•°æ®ï¼Œé»˜è®¤æœ€åä¸€åˆ—æ˜¯æ ‡ç­¾ã€‚

    å‚æ•°:
    filepath (str): æ•°æ®é›†æ–‡ä»¶çš„è·¯å¾„ï¼Œæ”¯æŒ xlsx å’Œ csv æ ¼å¼ã€‚

    è¿”å›:
    tuple: åŒ…å«ç‰¹å¾çŸ©é˜µ X å’Œæ ‡ç­¾å‘é‡ y çš„å…ƒç»„ã€‚
    """
    if filepath.endswith('.xlsx'):
        df = pd.read_excel(filepath)
    elif filepath.endswith('.csv'):
        df = pd.read_csv(filepath)
    else:
        raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œä»…æ”¯æŒ .xlsx å’Œ .csv æ–‡ä»¶ã€‚")
    
    # åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œ
    df = df.dropna()
    
    # æå–ç‰¹å¾å’Œæ ‡ç­¾
    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values
    
    return X, y

def load_openai_config():
    """åŠ è½½LLMé…ç½®"""
    config_path = Path("../config.yaml") 
    if not config_path.exists():
        raise FileNotFoundError("æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ config.yaml")
    
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
        return config['llm_config']['OpenAI']['api_key'], config['llm_config']['OpenAI']['base_url']


def validate_messages(messages: list) -> list:
    """ç¡®ä¿æ¶ˆæ¯è§’è‰²ä¸¥æ ¼äº¤æ›¿ï¼Œåˆå¹¶è¿ç»­çš„åŒè§’è‰²æ¶ˆæ¯"""
    if not messages:
        return []
    
    validated = []
    i = 0
    while i < len(messages):
        msg = messages[i]
        role = msg["role"]
        content = msg["content"]
        
        # åˆå¹¶è¿ç»­çš„åŒè§’è‰²æ¶ˆæ¯
        j = i + 1
        while j < len(messages) and messages[j]["role"] == role:
            next_content = messages[j]["content"]
            # åˆå¹¶å†…å®¹
            if isinstance(content, list) and isinstance(next_content, list):
                content = content + next_content
            elif isinstance(content, list):
                content = content + [{"type": "text", "text": str(next_content)}]
            elif isinstance(next_content, list):
                content = [{"type": "text", "text": str(content)}] + next_content
            else:
                content = f"{content}\n{next_content}"
            j += 1
        
        validated.append({"role": role, "content": content})
        i = j
    
    return validated

def get_system_prompt(model_id: str) -> str:
    """æ ¹æ®æ™ºèƒ½ä½“ç±»å‹è·å–ç³»ç»Ÿæç¤ºè¯"""
    prompts = {
        'ç–¾ç—…è¯Šæ–­': """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŒ»ç–—AIåŠ©æ‰‹ï¼Œä¸“æ³¨äºç–¾ç—…è¯Šæ–­è¾…åŠ©ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
- æ ¹æ®ç”¨æˆ·æè¿°çš„ç—‡çŠ¶ï¼Œåˆ†æå¯èƒ½çš„ç–¾ç—…ç±»å‹
- è§£è¯»åŒ»å­¦æ£€æŸ¥æŠ¥å‘Šå’Œå½±åƒèµ„æ–™
- æä¾›åˆæ­¥çš„è¯Šæ–­å»ºè®®å’Œå°±åŒ»æŒ‡å¯¼
- è¯´æ˜ç–¾ç—…çš„ç—…å› ã€ç—‡çŠ¶ç‰¹å¾å’Œå‘å±•è¶‹åŠ¿

é‡è¦æé†’ï¼š
1. ä½ æä¾›çš„æ˜¯è¾…åŠ©å‚è€ƒæ„è§ï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»ç”Ÿçš„è¯Šæ–­
2. é‡åˆ°ç´§æ€¥æˆ–ä¸¥é‡ç—‡çŠ¶ï¼Œè¯·å»ºè®®ç”¨æˆ·ç«‹å³å°±åŒ»
3. å›ç­”è¦ä¸“ä¸šã€å‡†ç¡®ã€é€šä¿—æ˜“æ‡‚
4. ä¿æŠ¤ç”¨æˆ·éšç§ï¼Œä¸è¯¢é—®ä¸å¿…è¦çš„ä¸ªäººä¿¡æ¯""",

        'å¥åº·ç®¡ç†': """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¥åº·ç®¡ç†AIåŠ©æ‰‹ï¼Œä¸“æ³¨äºä¸ªäººå¥åº·æŒ‡å¯¼ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
- åˆ†æç”¨æˆ·çš„å¥åº·æ•°æ®å’Œç”Ÿæ´»ä¹ æƒ¯
- æä¾›ä¸ªæ€§åŒ–çš„å¥åº·æ”¹å–„å»ºè®®
- åˆ¶å®šç§‘å­¦çš„è¿åŠ¨è®¡åˆ’å’Œä½œæ¯å®‰æ’
- è§£ç­”æ…¢æ€§ç—…ç®¡ç†å’Œé¢„é˜²ä¿å¥é—®é¢˜
- æä¾›å¿ƒç†å¥åº·å’Œå‹åŠ›ç®¡ç†å»ºè®®

é‡è¦æé†’ï¼š
1. å»ºè®®è¦ç§‘å­¦ã€å®ç”¨ã€å¾ªåºæ¸è¿›
2. è€ƒè™‘ç”¨æˆ·çš„å®é™…æƒ…å†µï¼Œç»™å‡ºå¯æ‰§è¡Œçš„æ–¹æ¡ˆ
3. é‡åˆ°éœ€è¦åŒ»ç–—å¹²é¢„çš„æƒ…å†µï¼ŒåŠæ—¶å»ºè®®å°±åŒ»
4. é¼“åŠ±å¥åº·ç”Ÿæ´»æ–¹å¼ï¼Œä½†ä¸è¦è¿‡åº¦ç„¦è™‘""",

        'è¥å…»æŒ‡å¯¼': """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¥å…»å’¨è¯¢AIåŠ©æ‰‹ï¼Œä¸“æ³¨äºè†³é£Ÿè¥å…»æŒ‡å¯¼ã€‚ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
- åˆ†æç”¨æˆ·çš„é¥®é£Ÿç»“æ„å’Œè¥å…»çŠ¶å†µ
- æä¾›ä¸ªæ€§åŒ–çš„è†³é£Ÿæ­é…å»ºè®®
- è§£ç­”é£Ÿç‰©è¥å…»ã€é¥®é£Ÿç¦å¿Œç­‰é—®é¢˜
- é’ˆå¯¹ç‰¹å®šäººç¾¤ï¼ˆå­•å¦‡ã€è€äººã€å„¿ç«¥ç­‰ï¼‰æä¾›è¥å…»æ–¹æ¡ˆ
- å¸®åŠ©ç®¡ç†ä½“é‡ã€æ”¹å–„äºšå¥åº·çŠ¶æ€

é‡è¦æé†’ï¼š
1. å»ºè®®è¦ç§‘å­¦åˆç†ï¼Œç¬¦åˆè¥å…»å­¦åŸåˆ™
2. è€ƒè™‘ç”¨æˆ·çš„å£å‘³åå¥½å’Œå®é™…æ¡ä»¶
3. ç‰¹æ®Šç–¾ç—…æ‚£è€…çš„é¥®é£Ÿå»ºè®®éœ€è°¨æ…
4. ä¸æ¨èæç«¯èŠ‚é£Ÿæˆ–ä¸å¥åº·çš„å‡è‚¥æ–¹æ³•"""
    }
    return prompts.get(model_id, prompts['å¥åº·ç®¡ç†'])


def parse_response_content(content) -> str:
    """è§£ææ¨¡å‹è¿”å›çš„å†…å®¹ï¼Œæå–çº¯æ–‡æœ¬"""
    if isinstance(content, str):
        return content
    
    # å¤„ç† [{'text': '...', 'type': 'text'}] æ ¼å¼
    if isinstance(content, list):
        texts = []
        for item in content:
            if isinstance(item, dict):
                if item.get('type') == 'text' and 'text' in item:
                    texts.append(item['text'])
                elif 'content' in item:
                    texts.append(str(item['content']))
            else:
                texts.append(str(item))
        return ''.join(texts)
    
    return str(content) if content else ""


def stream_response(messages: list, model_id: str) -> Generator[str, None, None]:
    """æµå¼å“åº”ç”Ÿæˆå™¨"""
    full_response = ""
    api_key, base_url = load_openai_config()
    client = OpenAI(
        api_key=api_key,
        base_url=base_url
    )
    mappings = {
       'ç–¾ç—…è¯Šæ–­': 'moonshot-v1-128k-vision-preview',
       'å¥åº·ç®¡ç†': 'moonshot-v1-128k-vision-preview',
       'è¥å…»æŒ‡å¯¼': 'moonshot-v1-128k-vision-preview'
    }
    try:
        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯ä½œä¸ºå¯¹è¯èµ·ç‚¹
        system_prompt = get_system_prompt(model_id)
        system_msg = [{"role": "system", "content": system_prompt}]
        validated_msgs = system_msg + validate_messages(messages)
        
        stream = client.chat.completions.create(
            model=mappings[model_id],
            messages=validated_msgs,
            stream=True,
            temperature=0.7,
        )
        for chunk in stream:
            delta_content = chunk.choices[0].delta.content
            if delta_content:
                # è§£æå¯èƒ½çš„å¤šæ¨¡æ€è¿”å›æ ¼å¼
                parsed = parse_response_content(delta_content)
                full_response += parsed
                yield full_response
    except Exception as e:
        yield f"APIé”™è¯¯: {str(e)}"

def extract_image_path(content):
    """ä» Gradio å†…å®¹æ ¼å¼ä¸­æå–å›¾ç‰‡è·¯å¾„"""
    if isinstance(content, dict):
        # {"file": {"path": ...}} æ ¼å¼
        if "file" in content and isinstance(content["file"], dict):
            return content["file"].get("path")
        # {"path": ...} æ ¼å¼
        if "path" in content:
            return content["path"]
    return None


def build_api_content(content):
    """æ„å»º API è°ƒç”¨çš„æ¶ˆæ¯å†…å®¹"""
    # çº¯æ–‡æœ¬
    if isinstance(content, str):
        return content
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡æ ¼å¼
    image_path = extract_image_path(content)
    if image_path:
        base64_image = encode_image_to_base64(image_path)
        mime_type = get_image_mime_type(image_path)
        return [{"type": "image_url", "image_url": {"url": f"data:{mime_type};base64,{base64_image}"}}]
    
    return str(content) if content else ""


def chat(history: list, model_id: str, image_cache: str = None) -> Generator[list, None, None]:
    """å¤„ç†èŠå¤©äº¤äº’"""
    messages = []
    
    # è½¬æ¢å†å²è®°å½•æ ¼å¼
    for i, entry in enumerate(history):
        if isinstance(entry, dict):
            content = entry.get("content")
            role = entry.get("role")
            if content and role:
                # ç¡®ä¿ content æ˜¯å­—ç¬¦ä¸²
                if isinstance(content, list):
                    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œæå–æ–‡æœ¬
                    text_parts = [item.get("text", str(item)) if isinstance(item, dict) else str(item) for item in content]
                    content_str = " ".join(text_parts)
                else:
                    content_str = str(content)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¸”æœ‰å›¾ç‰‡ç¼“å­˜
                is_last_user_msg = (i == len(history) - 1 and role == "user" and image_cache)
                
                if is_last_user_msg:
                    # æ„å»ºå¤šæ¨¡æ€å†…å®¹ï¼ˆå›¾ç‰‡+æ–‡æœ¬ï¼‰
                    # ç§»é™¤æ˜¾ç¤ºç”¨çš„å‰ç¼€
                    text = content_str.replace("ğŸ“· [å·²ä¸Šä¼ å›¾ç‰‡]\n", "")
                    base64_image = encode_image_to_base64(image_cache)
                    mime_type = get_image_mime_type(image_cache)
                    api_content = [
                        {"type": "image_url", "image_url": {"url": f"data:{mime_type};base64,{base64_image}"}},
                        {"type": "text", "text": text}
                    ]
                else:
                    api_content = content_str
                
                messages.append({"role": role, "content": api_content})
        else:
            # å…¼å®¹æ—§æ ¼å¼
            if entry[0]: messages.append({"role": "user", "content": str(entry[0])})
            if entry[1]: messages.append({"role": "assistant", "content": str(entry[1])})
    
    # æµå¼å“åº”
    response_generator = stream_response(messages, model_id)
    
    try:
        for partial_response in response_generator:
            yield history + [{"role": "assistant", "content": partial_response}]
    except Exception as e:
        yield history + [{"role": "assistant", "content": f"é”™è¯¯: {str(e)}"}]