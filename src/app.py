"""
æ™ºèƒ½åŒ»ç–—ç³»ç»Ÿä¸»å…¥å£
StarshotğŸŒŸ
"""
import gradio as gr
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, recall_score, f1_score

# å¯¼å…¥æ¨¡å—
from utils import load_data, chat, load_config
from utils.data_process import DataProcessor
from utils.plot import Visualizer
from utils.app_helpers import (
    load_preview_data,
    analyze_data,
    get_missing_info,
    get_outlier_info,
    get_distribution_info,
    get_correlation_info,
    process_data,
    download_report,
    download_chat_history,
    download_processed_data,
    prepare_for_llm,
    update_provider_info,
    user_input_handler,
    setup_frpc,
    select_example_data,
    send_to_training,
    global_model,
)
from models.svm import SVM
from models.logistic_regression import LogisticRegression
from models.random_forest import RandomForest


from web_design import create_layout, setup_events


# ==================== æ¨¡å‹è®­ç»ƒç›¸å…³ ====================

# å…¨å±€å˜é‡
_global_model = None
_global_test_data = None  # ä¿å­˜æµ‹è¯•é›† (X_test, y_test)


def get_file_columns(file):
    """è·å–æ–‡ä»¶çš„åˆ—åï¼Œç”¨äºæ›´æ–°ç‰¹å¾/æ ‡ç­¾é€‰æ‹©ä¸‹æ‹‰æ¡†"""
    if file is None:
        return gr.Dropdown(choices=[], value=[]), gr.Dropdown(choices=[], value=None)
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name, nrows=0)  # åªè¯»å–åˆ—å
        else:
            df = pd.read_excel(file.name, nrows=0)
        
        columns = df.columns.tolist()
        
        # ç‰¹å¾åˆ—ï¼šé»˜è®¤é€‰æ‹©é™¤æœ€åä¸€åˆ—å¤–çš„æ‰€æœ‰åˆ—
        # æ ‡ç­¾åˆ—ï¼šé»˜è®¤é€‰æ‹©æœ€åä¸€åˆ—
        return (
            gr.Dropdown(choices=columns, value=columns[:-1] if len(columns) > 1 else []),
            gr.Dropdown(choices=columns, value=columns[-1] if columns else None)
        )
    except Exception as e:
        print(f"è¯»å–åˆ—åå¤±è´¥: {e}")
        return gr.Dropdown(choices=[], value=[]), gr.Dropdown(choices=[], value=None)


def train_model(
    file,
    feature_cols,
    label_col,
    split_method,
    test_size,
    k_folds,
    random_seed,
    model_type,
    rf_n_estimators=100,
    rf_max_depth=None,
    rf_max_features="sqrt",
    svm_kernel="linear",
    svm_C=1.0,
    svm_gamma="scale",
    lr_penalty="l2",
    lr_C=1.0,
    lr_solver="lbfgs"
):
    """è®­ç»ƒæ¨¡å‹ï¼ˆæ”¯æŒè‡ªå®šä¹‰ç‰¹å¾åˆ—å’Œæ ‡ç­¾åˆ—ï¼‰"""
    global _global_model, _global_test_data
    from sklearn.model_selection import cross_val_score, StratifiedKFold
    import numpy as np
    
    if file is None:
        return "è¯·å…ˆä¸Šä¼ è®­ç»ƒæ•°æ®ï¼"
    
    try:
        # åŠ è½½æ•°æ®
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        df = df.dropna()
        
        # ç¡®å®šæ ‡ç­¾åˆ—
        if label_col and label_col in df.columns:
            y = df[label_col].values
        else:
            y = df.iloc[:, -1].values
            label_col = df.columns[-1]
        
        # ç¡®å®šç‰¹å¾åˆ—
        if feature_cols and len(feature_cols) > 0:
            # è¿‡æ»¤æ‰ä¸å­˜åœ¨çš„åˆ—å’Œæ ‡ç­¾åˆ—
            valid_features = [c for c in feature_cols if c in df.columns and c != label_col]
            if valid_features:
                X = df[valid_features].values
                feature_info = f"å·²é€‰æ‹© {len(valid_features)} ä¸ªç‰¹å¾"
            else:
                # ä½¿ç”¨é™¤æ ‡ç­¾å¤–çš„æ‰€æœ‰åˆ—
                X = df.drop(columns=[label_col]).values
                feature_info = f"ä½¿ç”¨å…¨éƒ¨ {X.shape[1]} ä¸ªç‰¹å¾ï¼ˆé»˜è®¤ï¼‰"
        else:
            # ä½¿ç”¨é™¤æ ‡ç­¾å¤–çš„æ‰€æœ‰åˆ—
            X = df.drop(columns=[label_col]).values
            feature_info = f"ä½¿ç”¨å…¨éƒ¨ {X.shape[1]} ä¸ªç‰¹å¾ï¼ˆé»˜è®¤ï¼‰"
        
        random_seed = int(random_seed) if random_seed else 42
        
        # åˆ›å»ºæ¨¡å‹
        if model_type == "Random Forest":
            model = RandomForest(
                n_estimators=rf_n_estimators,
                max_depth=rf_max_depth,
                max_features=rf_max_features,
                random_state=random_seed
            )
        elif model_type == "SVM":
            model = SVM(
                kernel=svm_kernel,
                C=svm_C,
                gamma=svm_gamma
            )
        else:  # Logistic Regression
            model = LogisticRegression(
                penalty=lr_penalty,
                C=lr_C,
                solver=lr_solver
            )
        
        # æ£€æŸ¥ç±»åˆ«åˆ†å¸ƒï¼Œåˆ¤æ–­æ˜¯å¦å¯ä»¥åˆ†å±‚é‡‡æ ·
        from collections import Counter
        class_counts = Counter(y)
        min_class_count = min(class_counts.values())
        
        # KæŠ˜äº¤å‰éªŒè¯
        if split_method == "KæŠ˜äº¤å‰éªŒè¯":
            k = int(k_folds)
            
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥è¿›è¡Œåˆ†å±‚KæŠ˜
            if min_class_count >= k:
                cv = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_seed)
                stratify_info = "åˆ†å±‚"
            else:
                from sklearn.model_selection import KFold
                cv = KFold(n_splits=k, shuffle=True, random_state=random_seed)
                stratify_info = "æ™®é€š"
            
            # ä½¿ç”¨åº•å±‚ sklearn æ¨¡å‹è¿›è¡Œäº¤å‰éªŒè¯
            sklearn_model = model.model  # è·å–åº•å±‚ sklearn æ¨¡å‹
            
            acc_scores = cross_val_score(sklearn_model, X, y, cv=cv, scoring='accuracy')
            f1_scores = cross_val_score(sklearn_model, X, y, cv=cv, scoring='f1_macro')
            recall_scores = cross_val_score(sklearn_model, X, y, cv=cv, scoring='recall_macro')
            
            # åˆ’åˆ†ä¸€éƒ¨åˆ†æ•°æ®ç”¨äºè¯„ä¼°å¯è§†åŒ–
            if min_class_count >= 2:
                X_train, X_eval, y_train, y_eval = train_test_split(
                    X, y, test_size=0.2, random_state=random_seed, stratify=y
                )
            else:
                X_train, X_eval, y_train, y_eval = train_test_split(
                    X, y, test_size=0.2, random_state=random_seed
                )
            
            # ç”¨å…¨éƒ¨æ•°æ®è®­ç»ƒæœ€ç»ˆæ¨¡å‹
            model.train(X, y)
            _global_model = model
            _global_test_data = (X_eval, y_eval)  # ä¿å­˜è¯„ä¼°æ•°æ®
            
            result = f"ğŸ”„ {k}æŠ˜{stratify_info}äº¤å‰éªŒè¯å®Œæˆï¼\n\n"
            if stratify_info == "æ™®é€š":
                result += f"âš ï¸ éƒ¨åˆ†ç±»åˆ«æ ·æœ¬è¿‡å°‘ï¼ˆæœ€å°ç±»åˆ«ä»…{min_class_count}ä¸ªï¼‰ï¼Œå·²ä½¿ç”¨æ™®é€šKæŠ˜\n\n"
            result += f"ğŸ“Š æ•°æ®: {len(X)} æ ·æœ¬ Ã— {X.shape[1]} ç‰¹å¾\n"
            result += f"   æ ‡ç­¾åˆ—: {label_col} | {feature_info}\n"
            result += f"   ç±»åˆ«åˆ†å¸ƒ: {dict(class_counts)}\n\n"
            result += f"ğŸ“Š å‡†ç¡®ç‡: {acc_scores.mean():.3f} Â± {acc_scores.std():.3f}\n"
            result += f"   å„æŠ˜: {', '.join([f'{s:.3f}' for s in acc_scores])}\n\n"
            result += f"ğŸ“Š å¬å›ç‡: {recall_scores.mean():.3f} Â± {recall_scores.std():.3f}\n"
            result += f"   å„æŠ˜: {', '.join([f'{s:.3f}' for s in recall_scores])}\n\n"
            result += f"ğŸ“Š F1åˆ†æ•°: {f1_scores.mean():.3f} Â± {f1_scores.std():.3f}\n"
            result += f"   å„æŠ˜: {', '.join([f'{s:.3f}' for s in f1_scores])}\n\n"
            result += f"âœ… æœ€ç»ˆæ¨¡å‹å·²ç”¨å…¨éƒ¨æ•°æ®è®­ç»ƒï¼Œè¯„ä¼°æ•°æ®å·²ä¿å­˜ï¼ˆ{len(X_eval)}æ ·æœ¬ï¼‰"
            
            return result
        
        # ç®€å•åˆ‡åˆ†
        else:
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆ†å±‚é‡‡æ ·ï¼ˆæ¯ä¸ªç±»åˆ«è‡³å°‘éœ€è¦2ä¸ªæ ·æœ¬ï¼‰
            if min_class_count >= 2:
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=test_size, random_state=random_seed, stratify=y
                )
                stratify_info = "ï¼ˆåˆ†å±‚é‡‡æ ·ï¼‰"
            else:
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=test_size, random_state=random_seed
                )
                stratify_info = "ï¼ˆæ™®é€šéšæœºï¼Œéƒ¨åˆ†ç±»åˆ«æ ·æœ¬è¿‡å°‘ï¼‰"
            
            model.train(X_train, y_train)
            _global_model = model
            _global_test_data = (X_test, y_test)  # ä¿å­˜æµ‹è¯•é›†ç”¨äºè¯„ä¼°
            
            result = f"âœ… ç®€å•åˆ‡åˆ†è®­ç»ƒå®Œæˆï¼{stratify_info}\n\n"
            result += f"ğŸ“Š æ•°æ®: {len(X)} æ ·æœ¬ Ã— {X.shape[1]} ç‰¹å¾\n"
            result += f"   æ ‡ç­¾åˆ—: {label_col} | {feature_info}\n\n"
            result += f"ğŸ“Š æ•°æ®åˆ‡åˆ†:\n"
            result += f"   è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬ ({1-test_size:.0%})\n"
            result += f"   æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬ ({test_size:.0%})\n\n"
            result += f"ğŸ“Š ç±»åˆ«åˆ†å¸ƒ: {dict(class_counts)}\n\n"
            result += f"ğŸ”„ æ­£åœ¨è‡ªåŠ¨è¿›è¡Œæ¨¡å‹è¯„ä¼°..."
            
            return result
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        return f"è®­ç»ƒå‡ºé”™: {str(e)}"


def make_prediction(pred_file):
    """æ‰¹é‡é¢„æµ‹"""
    global _global_model
    
    if _global_model is None:
        return "âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼"
    
    try:
        X_pred, _ = load_data(pred_file.name)
        predictions = _global_model.predict(X_pred)
        
        return pd.DataFrame({
            'æ ·æœ¬åºå·': range(1, len(predictions)+1),
            'é¢„æµ‹ç»“æœ': predictions
        })
    
    except Exception as e:
        return f"é¢„æµ‹å‡ºé”™: {str(e)}"


def evaluate_model(file=None):
    """
    æ¨¡å‹è¯„ä¼°
    - å¦‚æœæä¾› fileï¼Œä½¿ç”¨ä¸Šä¼ çš„æ–‡ä»¶è¯„ä¼°
    - å¦‚æœ file ä¸ºç©ºï¼Œä½¿ç”¨è®­ç»ƒæ—¶ä¿å­˜çš„æµ‹è¯•é›†
    """
    global _global_model, _global_test_data
    
    if _global_model is None:
        empty_df = pd.DataFrame({"æç¤º": ["è¯·å…ˆè®­ç»ƒæ¨¡å‹"]})
        return "âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼", empty_df, None, None, None
    
    # è·å–è¯„ä¼°æ•°æ®
    if file is not None:
        X, y = load_data(file.name)
        data_source = "ä¸Šä¼ æ•°æ®"
    elif _global_test_data is not None:
        X, y = _global_test_data
        data_source = "è®­ç»ƒæµ‹è¯•é›†"
    else:
        empty_df = pd.DataFrame({"æç¤º": ["æ²¡æœ‰å¯ç”¨çš„è¯„ä¼°æ•°æ®"]})
        return "âš ï¸ æ²¡æœ‰å¯ç”¨çš„è¯„ä¼°æ•°æ®ï¼Œè¯·ä¸Šä¼ æ–‡ä»¶æˆ–å…ˆè®­ç»ƒæ¨¡å‹", empty_df, None, None, None
    
    try:
        # è®¡ç®—é¢„æµ‹å’ŒæŒ‡æ ‡
        preds = _global_model.predict(X)
        acc = accuracy_score(y, preds)
        rec = recall_score(y, preds, average='macro')
        f1 = f1_score(y, preds, average='macro')
        
        # åˆ›å»ºæŒ‡æ ‡è¡¨æ ¼
        metrics_df = pd.DataFrame({
            "æŒ‡æ ‡": ["å‡†ç¡®ç‡ (Accuracy)", "å¬å›ç‡ (Recall)", "F1åˆ†æ•° (F1-Score)", "æ ·æœ¬æ•°"],
            "å€¼": [f"{acc:.4f}", f"{rec:.4f}", f"{f1:.4f}", str(len(y))]
        })
        
        # å¯è§†åŒ–
        classes = np.unique(y)
        viz = Visualizer(classes)
        
        y_proba = _global_model.predict_proba(X)
        roc_fig = viz.plot_roc(y, y_proba)
        pr_fig = viz.plot_pr(y, y_proba)
        
        eval_metrics = _global_model.evaluate(X, y)
        confusion_matrix_fig = viz.plot_confusion_matrix(eval_metrics['confusion_matrix'])
        
        status = f"âœ… ä½¿ç”¨ **{data_source}** è¯„ä¼°å®Œæˆ | æ ·æœ¬æ•°: {len(y)}"
        
        return status, metrics_df, roc_fig, pr_fig, confusion_matrix_fig
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        empty_df = pd.DataFrame({"é”™è¯¯": [str(e)]})
        return f"âŒ è¯„ä¼°å‡ºé”™: {str(e)}", empty_df, None, None, None


def toggle_params(model_type):
    """åˆ‡æ¢æ¨¡å‹å‚æ•°æ˜¾ç¤º"""
    return (
        gr.Accordion(visible=model_type == "Random Forest"),
        gr.Accordion(visible=model_type == "SVM"),
        gr.Accordion(visible=model_type == "Logistic Regression")
    )


def toggle_split_params(split_method):
    """åˆ‡æ¢æ•°æ®åˆ‡åˆ†å‚æ•°æ˜¾ç¤º"""
    is_simple = split_method == "ç®€å•åˆ‡åˆ†"
    return (
        gr.Slider(visible=is_simple),   # test_size
        gr.Slider(visible=not is_simple)  # k_folds
    )


# ==================== åˆ›å»ºåº”ç”¨ ====================

# åˆ›å»º UI å¸ƒå±€
demo, components = create_layout()

# å‡†å¤‡äº‹ä»¶å¤„ç†å‡½æ•°
handlers = {
    'select_example_data': select_example_data,
    'load_preview_data': load_preview_data,
    'analyze_data': analyze_data,
    'get_missing_info': get_missing_info,
    'get_outlier_info': get_outlier_info,
    'get_distribution_info': get_distribution_info,
    'get_correlation_info': get_correlation_info,
    'process_data': process_data,
    'download_report': download_report,
    'download_chat_history': download_chat_history,
    'download_processed_data': download_processed_data,
    'prepare_for_llm': prepare_for_llm,
    'send_to_training': send_to_training,
    'update_provider_info': update_provider_info,
    'user_input_handler': user_input_handler,
    'chat': chat,
    'train_model': train_model,
    'make_prediction': make_prediction,
    'evaluate_model': evaluate_model,
    'toggle_params': toggle_params,
    'toggle_split_params': toggle_split_params,
    'get_file_columns': get_file_columns,
}

# åœ¨ Blocks ä¸Šä¸‹æ–‡ä¸­è®¾ç½®äº‹ä»¶ç»‘å®š
with demo:
    setup_events(components, handlers)


# ==================== å¯åŠ¨é…ç½® ====================

if __name__ == "__main__":
    import sys
    
    PORT = 7860
    
    # æ£€æŸ¥å¯åŠ¨æ¨¡å¼
    use_share = "--share" in sys.argv
    
    # å¦‚æœä½¿ç”¨ shareï¼Œè‡ªåŠ¨é…ç½® frpc
    if use_share:
        setup_frpc()
    
    print("=" * 50)
    print("ğŸ¥ æ™ºèƒ½åŒ»ç–—ç³»ç»Ÿå¯åŠ¨ä¸­...")
    print("=" * 50)
    
    public_url = None
    
    print(f"ğŸ“ æœ¬åœ°è®¿é—®: http://localhost:{PORT}")
    print(f"ğŸ“ å±€åŸŸç½‘: http://0.0.0.0:{PORT}")
    print("=" * 50)
    print("å¯åŠ¨å‚æ•°:")
    print("  --share  ä½¿ç”¨ Gradio å†…ç½®åˆ†äº«(éœ€ç½‘ç»œæ”¯æŒ)")
    print("=" * 50)
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    import os
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    example_dir = os.path.join(project_root, "example")
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=PORT,
        share=use_share,
        show_error=True,
        allowed_paths=[example_dir],  # å…è®¸è®¿é—® example æ–‡ä»¶å¤¹
    )
