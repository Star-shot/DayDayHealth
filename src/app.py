import gradio as gr
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, recall_score, f1_score
from utils import load_data, chat, load_config
from utils.data_process import DataProcessor
from models.svm import SVM
from models.logistic_regression import LogisticRegression
from models.random_forest import RandomForest
from plot import Visualizer  # å¯¼å…¥å¯è§†åŒ–ç±»


# å…¨å±€å˜é‡å­˜å‚¨æ¨¡å‹å’Œæ•°æ®å¤„ç†å™¨
global_model = None
global_processor = None


# ==================== æ•°æ®é¢„å¤„ç†å‡½æ•° ====================

def load_preview_data(file):
    """åŠ è½½æ•°æ®å¹¶é¢„è§ˆ"""
    if file is None:
        return None, "è¯·å…ˆä¸Šä¼ æ–‡ä»¶"
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        info = f"æ•°æ®å½¢çŠ¶: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—\n"
        info += f"ç¼ºå¤±å€¼æ€»æ•°: {df.isnull().sum().sum()}"
        return df.head(20), info
    except Exception as e:
        return None, f"åŠ è½½å¤±è´¥: {str(e)}"


def get_missing_info(file):
    """è·å–ç¼ºå¤±å€¼ä¿¡æ¯"""
    if file is None:
        return None, None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        processor = DataProcessor(df)
        missing_info = processor.get_missing_info()
        missing_fig = processor.plot_missing_matrix()
        
        return missing_info, missing_fig
    except Exception as e:
        return None, None


def get_outlier_info(file):
    """è·å–å¼‚å¸¸å€¼ä¿¡æ¯å¹¶ç»˜åˆ¶ç®±çº¿å›¾"""
    if file is None:
        return None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        processor = DataProcessor(df)
        fig = processor.plot_boxplot()
        return fig
    except Exception as e:
        return None


def get_distribution_info(file):
    """è·å–æ•°æ®åˆ†å¸ƒä¿¡æ¯"""
    if file is None:
        return None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        processor = DataProcessor(df)
        fig = processor.plot_distribution()
        return fig
    except Exception as e:
        return None


def get_correlation_info(file):
    """è·å–ç›¸å…³æ€§çƒ­åŠ›å›¾"""
    if file is None:
        return None, None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        processor = DataProcessor(df)
        fig = processor.plot_correlation_heatmap()
        high_corr = processor.get_high_correlation_pairs()
        
        return fig, high_corr
    except Exception as e:
        return None, None


def process_data(file, fill_strategy, outlier_method):
    """æ‰§è¡Œæ•°æ®é¢„å¤„ç†"""
    global global_processor
    
    if file is None:
        return None, "è¯·å…ˆä¸Šä¼ æ–‡ä»¶"
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        processor = DataProcessor(df)
        
        # ç¼ºå¤±å€¼å¤„ç†
        processor.fill_missing(strategy=fill_strategy)
        
        # å¼‚å¸¸å€¼å¤„ç†
        processor.handle_outliers(method=outlier_method)
        
        global_processor = processor
        
        # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
        log = processor.get_processing_log()
        report = f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼\n\nå¤„ç†æ­¥éª¤:\n"
        report += "\n".join([f"â€¢ {item}" for item in log])
        report += f"\n\nå¤„ç†åæ•°æ®: {processor.get_data().shape[0]} è¡Œ Ã— {processor.get_data().shape[1]} åˆ—"
        
        return processor.get_data().head(20), report
    except Exception as e:
        return None, f"å¤„ç†å¤±è´¥: {str(e)}"


def download_processed_data():
    """ä¸‹è½½å¤„ç†åçš„æ•°æ®"""
    global global_processor
    
    if global_processor is None:
        return None
    
    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    output_path = "output/processed_data.csv"
    global_processor.get_data().to_csv(output_path, index=False)
    return output_path

# æ¨¡å‹è®­ç»ƒå‡½æ•°ï¼ˆä½¿ç”¨è‡ªå®šä¹‰SVMï¼‰
def train_model(
    file, 
    model_type,
    # éšæœºæ£®æ—å‚æ•°
    rf_n_estimators=100,
    rf_max_depth=None,
    rf_max_features="sqrt",
    # SVMå‚æ•°
    svm_kernel="linear",
    svm_C=1.0,
    svm_gamma="scale",
    # é€»è¾‘å›å½’å‚æ•° 
    lr_penalty="l2",
    lr_C=1.0,
    lr_solver="lbfgs"
):
    global global_model
    try:
        X, y = load_data(file.name)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        if model_type == "Random Forest":
            model = RandomForest(
                n_estimators=rf_n_estimators,
                max_depth=rf_max_depth if rf_max_depth > 0 else None,
                max_features=rf_max_features
            )
        elif model_type == "SVM":
            model = SVM(
                kernel=svm_kernel,
                C=svm_C,
                gamma=svm_gamma
            )
        elif model_type == "Logistic Regression":
            model = LogisticRegression(
                penalty=lr_penalty,
                C=lr_C,
                solver=lr_solver
            )
            
        model.train(X_train, y_train)
        
        preds = model.predict(X_test)
        acc = accuracy_score(y_test, preds)
        rec = recall_score(y_test, preds, average='macro')
        f1 = f1_score(y_test, preds, average='macro')
        
        global_model = model
        
        return f"è®­ç»ƒå®Œæˆï¼\nå‡†ç¡®ç‡: {acc:.3f}\nå¬å›ç‡: {rec:.3f}\nF1åˆ†æ•°: {f1:.3f}"
    
    except Exception as e:
        return f"è®­ç»ƒå‡ºé”™: {str(e)}"

# é¢„æµ‹å‡½æ•°
def make_prediction(pred_file):
    if global_model is None:
        return "âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼"
    
    try:
        X_pred, _ = load_data(pred_file.name)
        predictions = global_model.predict(X_pred)
        
        return pd.DataFrame({
            'æ ·æœ¬åºå·': range(1, len(predictions)+1),
            'é¢„æµ‹ç»“æœ': predictions
        })
    
    except Exception as e:
        return f"é¢„æµ‹å‡ºé”™: {str(e)}"
    
def evaluate_model(file):
    if global_model is None:
        return "âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼"
    if not file:
        return "âš ï¸ è¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼"
    # try:

    X, y = load_data(file.name)
    df = pd.DataFrame(X)
    df['æ ‡ç­¾'] = y
    # æå–ç±»åˆ«
    classes = df['æ ‡ç­¾'].unique()
    viz = Visualizer(classes)
    y_proba = global_model.predict_proba(X)
    roc_fig = viz.plot_roc(y, y_proba)
    pr_fig = viz.plot_pr(y, y_proba)
    metrics = global_model.evaluate(X, y)
    confusion_matrix_fig = viz.plot_confusion_matrix(metrics['confusion_matrix'])
    return df, roc_fig, pr_fig, confusion_matrix_fig

                # åŠ¨æ€æ˜¾ç¤ºå‚æ•°åŒºçš„å›è°ƒå‡½æ•°
def toggle_params(model_type):
    return {
        rf_params: gr.Accordion(visible=model_type == "Random Forest"),
        svm_params: gr.Accordion(visible=model_type == "SVM"),
        lr_params: gr.Accordion(visible=model_type == "Logistic Regression")
    }     
        
# ç•Œé¢å¸ƒå±€
with gr.Blocks() as demo:
    gr.Markdown("# æ™ºèƒ½åŒ»ç–—ç³»ç»Ÿ")
    
    with gr.Row():
        # å·¦ä¾§é¢æ¿
        with gr.Column(scale=2):
            with gr.Tab("æ•°æ®å¤„ç†"):
                with gr.Row():
                    data_file = gr.File(
                        label="ä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼ˆCSV/XLSXï¼‰",
                        file_types=[".csv", ".xlsx"]
                    )
                    data_info = gr.Textbox(label="æ•°æ®ä¿¡æ¯", lines=2)
                
                data_output = gr.DataFrame(label="æ•°æ®é¢„è§ˆ", interactive=False)
                
                with gr.Accordion("æ•°æ®åˆ†æ", open=False):
                    with gr.Tab("ç¼ºå¤±å€¼åˆ†æ"):
                        missing_btn = gr.Button("åˆ†æç¼ºå¤±å€¼", size="sm")
                        missing_info = gr.DataFrame(label="ç¼ºå¤±å€¼ç»Ÿè®¡")
                        missing_plot = gr.Plot(label="ç¼ºå¤±å€¼çŸ©é˜µå›¾")
                    
                    with gr.Tab("å¼‚å¸¸å€¼åˆ†æ"):
                        outlier_btn = gr.Button("åˆ†æå¼‚å¸¸å€¼", size="sm")
                        outlier_plot = gr.Plot(label="ç®±çº¿å›¾")
                    
                    with gr.Tab("æ•°æ®åˆ†å¸ƒ"):
                        dist_btn = gr.Button("åˆ†æåˆ†å¸ƒ", size="sm")
                        dist_plot = gr.Plot(label="åˆ†å¸ƒå›¾")
                    
                    with gr.Tab("ç›¸å…³æ€§åˆ†æ"):
                        corr_btn = gr.Button("åˆ†æç›¸å…³æ€§", size="sm")
                        corr_plot = gr.Plot(label="ç›¸å…³æ€§çƒ­åŠ›å›¾")
                        high_corr_df = gr.DataFrame(label="é«˜ç›¸å…³ç‰¹å¾å¯¹ (|r| > 0.8)")
                
                gr.Markdown("### æ•°æ®é¢„å¤„ç†")
                with gr.Row():
                    fill_strategy = gr.Dropdown(
                        choices=["auto", "median", "mean", "mode", "knn", "drop"],
                        value="auto",
                        label="ç¼ºå¤±å€¼å¤„ç†ç­–ç•¥"
                    )
                    outlier_method = gr.Dropdown(
                        choices=["cap", "drop", "median"],
                        value="cap",
                        label="å¼‚å¸¸å€¼å¤„ç†æ–¹æ³•"
                    )
                
                with gr.Row():
                    preprocess_btn = gr.Button("æ‰§è¡Œé¢„å¤„ç†", variant="primary")
                    download_btn = gr.Button("ä¸‹è½½å¤„ç†åæ•°æ®", variant="secondary")
                
                preprocess_output = gr.Textbox(label="å¤„ç†æŠ¥å‘Š", lines=6)
                processed_file = gr.File(label="ä¸‹è½½æ–‡ä»¶", visible=False)
            with gr.Tab("æ¨¡å‹è®­ç»ƒ"):
                train_file = gr.File(
                    label="ä¸Šä¼ è®­ç»ƒæ–‡ä»¶ï¼ˆCSV/XLSXï¼‰",
                    file_types=[".csv", ".xlsx"]
                )
                model_choice = gr.Dropdown(
                    choices=["Random Forest", "SVM", "Logistic Regression"],
                    label="é€‰æ‹©æ¨¡å‹",
                    value="Random Forest"
                )
                # å„æ¨¡å‹å‚æ•°åŒº
                with gr.Accordion("éšæœºæ£®æ—å‚æ•°", visible=True) as rf_params:  # é»˜è®¤æ˜¾ç¤º
                    rf_n_estimators = gr.Slider(50, 500, value=100, step=50, label="æ ‘çš„æ•°é‡ (n_estimators)")
                    rf_max_depth = gr.Slider(2, 50, value=None, step=1, label="æœ€å¤§æ·±åº¦ (max_depth)")
                    rf_max_features = gr.Dropdown(
                        ["sqrt", "log2", 0.5, 0.8], 
                        value="sqrt", 
                        label="æœ€å¤§ç‰¹å¾æ•° (max_features)"
                    )
                
                with gr.Accordion("SVMå‚æ•°", visible=False) as svm_params:
                    svm_kernel = gr.Dropdown(
                        ["linear", "poly", "rbf", "sigmoid"],
                        value="linear",
                        label="æ ¸å‡½æ•° (kernel)"
                    )
                    svm_C = gr.Slider(0.1, 10.0, value=1.0, step=0.1, label="æ­£åˆ™åŒ–å¼ºåº¦ (C)")
                    svm_gamma = gr.Dropdown(
                        ["scale", "auto"],
                        value="scale",
                        label="æ ¸ç³»æ•° (gamma)"
                    )
                
                with gr.Accordion("é€»è¾‘å›å½’å‚æ•°", visible=False) as lr_params:
                    lr_penalty = gr.Dropdown(
                        ["l2", "l1", "elasticnet", "none"],
                        value="l2",
                        label="æ­£åˆ™åŒ–ç±»å‹ (penalty)"
                    )
                    lr_C = gr.Slider(0.01, 10.0, value=1.0, step=0.1, label="æ­£åˆ™åŒ–å¼ºåº¦ (C)")
                    lr_solver = gr.Dropdown(
                        ["lbfgs", "sag", "saga", "newton-cg", "liblinear"],
                        value="lbfgs",
                        label="ä¼˜åŒ–ç®—æ³• (solver)"
                    )
   
                model_choice.change(
                    fn=toggle_params,
                    inputs=model_choice,
                    outputs=[rf_params, svm_params, lr_params]
                )
                train_btn = gr.Button("å¼€å§‹è®­ç»ƒ", variant="primary") 
                train_output = gr.Textbox(
                    label="è®­ç»ƒç»“æœ",
                    interactive=False,
                    placeholder="è®­ç»ƒç»“æœå°†æ˜¾ç¤ºåœ¨æ­¤å¤„..."
                )
            with gr.Tab("æ¨¡å‹è¯„ä¼°"):
                # dataframe
                # å››ä¸ªç»˜å›¾åŒº
                # ä¸Šä¼ æ–‡ä»¶
                eval_file = gr.File(
                    label="ä¸Šä¼ è¯„ä¼°æ–‡ä»¶ï¼ˆCSV/XLSXï¼‰",
                    file_types=[".csv", ".xlsx"]
                )
                # å¼€å§‹è¯„ä¼°æŒ‰é’®
                eval_btn = gr.Button("å¼€å§‹è¯„ä¼°", variant="secondary")
                dataframe_component = gr.DataFrame(
                    label="æ¨¡å‹æŒ‡æ ‡",
                )
                roc_curve_plot = gr.Plot(label="ROCæ›²çº¿")
                pr_curve_plot = gr.Plot(label="PRæ›²çº¿")
                confusion_matrix_plot = gr.Plot(label="æ··æ·†çŸ©é˜µ")
                
                
            with gr.Tab("æ‰¹é‡é¢„æµ‹"):
                pred_file = gr.File(
                    label="ä¸Šä¼ é¢„æµ‹æ–‡ä»¶ï¼ˆCSV/XLSXï¼‰",
                    file_types=[".csv", ".xlsx"]
                )
                pred_btn = gr.Button("å¼€å§‹é¢„æµ‹", variant="secondary")
                pred_output = gr.Dataframe(
                    label="é¢„æµ‹ç»“æœ",
                    headers=["æ ·æœ¬åºå·", "é¢„æµ‹ç»“æœ"],
                    interactive=False
                )
                
            with gr.Tab("å¯è§†åŒ–"):
                pass
            #TODO
                

        # å³ä¾§èŠå¤©é¢æ¿
        with gr.Column(scale=1):
            chatbot = gr.Chatbot(
                label="æ™ºèƒ½åŠ©æ‰‹",
                height=400,
                # bubble_full_width=False,
            )
            with gr.Row():
                msg = gr.Textbox(
                    label="è¾“å…¥æ¶ˆæ¯",
                    placeholder="è¾“å…¥é—®é¢˜åæŒ‰å›è½¦å‘é€",
                    max_lines=3,
                    scale=4
                )
                img_input = gr.Image(
                    label="ä¸Šä¼ å›¾ç‰‡",
                    type="filepath",
                    scale=1
                )
            model_id = gr.Dropdown(
                label="åŒ»ç–—æ™ºèƒ½ä½“",
                value="å¥åº·ç®¡ç†",
                choices=["ç–¾ç—…è¯Šæ–­", "å¥åº·ç®¡ç†", "è¥å…»æŒ‡å¯¼"]
            )
            provider_info = gr.Markdown(value="**å½“å‰æ¨¡å‹**: qwen / qwen-max")
            send_btn = gr.Button("å‘é€", variant="primary", size='sm')
            clear_btn = gr.ClearButton([msg, chatbot, img_input], size='sm')
            
            def update_provider_info(agent_id):
                """æ›´æ–°æ˜¾ç¤ºçš„æä¾›å•†ä¿¡æ¯"""
                try:
                    config = load_config()
                    agent_config = config.get('agent_models', {}).get(agent_id, {})
                    provider = agent_config.get('provider', config.get('default_provider', 'kimi'))
                    model_type = agent_config.get('model', 'default')
                    
                    # è·å–å®é™…æ¨¡å‹åç§°
                    providers = config.get('llm_providers', {})
                    model_name = providers.get(provider, {}).get('models', {}).get(model_type, 'unknown')
                    
                    return f"**å½“å‰æ¨¡å‹**: {provider} / {model_name}"
                except:
                    return "**å½“å‰æ¨¡å‹**: é…ç½®åŠ è½½å¤±è´¥"
            
            model_id.change(
                fn=update_provider_info,
                inputs=model_id,
                outputs=provider_info
            )
            
            # ç”¨äºå­˜å‚¨å›¾ç‰‡è·¯å¾„ï¼Œä¾› API è°ƒç”¨ä½¿ç”¨
            image_cache = gr.State(None)
            
            def user(user_message, image, history, img_cache):
                """å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆæ–‡æœ¬+å›¾ç‰‡ï¼‰"""
                if not user_message and not image:
                    return "", None, history, img_cache
                
                new_history = list(history)
                
                # æ„å»ºæ˜¾ç¤ºæ–‡æœ¬
                if image:
                    text = user_message or "è¯·åˆ†æè¿™å¼ å›¾ç‰‡"
                    display_text = f"ğŸ“· [å·²ä¸Šä¼ å›¾ç‰‡]\n{text}"
                    img_cache = image  # ç¼“å­˜å›¾ç‰‡è·¯å¾„ä¾› API ä½¿ç”¨
                else:
                    display_text = user_message
                    img_cache = None
                
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆçº¯æ–‡æœ¬æ ¼å¼ï¼ŒGradio å…¼å®¹ï¼‰
                new_history.append({"role": "user", "content": display_text})
                    
                return "", None, new_history, img_cache

    # ==================== äº‹ä»¶ç»‘å®š ====================
    
    # æ•°æ®å¤„ç†äº‹ä»¶
    data_file.change(
        fn=load_preview_data,
        inputs=data_file,
        outputs=[data_output, data_info]
    )
    
    missing_btn.click(
        fn=get_missing_info,
        inputs=data_file,
        outputs=[missing_info, missing_plot]
    )
    
    outlier_btn.click(
        fn=get_outlier_info,
        inputs=data_file,
        outputs=outlier_plot
    )
    
    dist_btn.click(
        fn=get_distribution_info,
        inputs=data_file,
        outputs=dist_plot
    )
    
    corr_btn.click(
        fn=get_correlation_info,
        inputs=data_file,
        outputs=[corr_plot, high_corr_df]
    )
    
    preprocess_btn.click(
        fn=process_data,
        inputs=[data_file, fill_strategy, outlier_method],
        outputs=[data_output, preprocess_output]
    )
    
    download_btn.click(
        fn=download_processed_data,
        outputs=processed_file
    )
    
    # æ¨¡å‹è®­ç»ƒäº‹ä»¶
    train_btn.click(
        fn=train_model,
        inputs=[
            train_file, 
            model_choice,      # æ¨¡å‹ç±»å‹
            # éšæœºæ£®æ—å‚æ•°
            rf_n_estimators, 
            rf_max_depth, 
            rf_max_features,
            # SVMå‚æ•°
            svm_kernel,
            svm_C,
            svm_gamma,
            # é€»è¾‘å›å½’å‚æ•°
            lr_penalty,
            lr_C,
            lr_solver
        ],
        outputs=train_output
    )

    
    eval_btn.click(
        evaluate_model,
        inputs=eval_file,
        outputs=[dataframe_component, roc_curve_plot, pr_curve_plot, confusion_matrix_plot]
    )
    
    pred_btn.click(
        make_prediction,
        inputs=pred_file,
        outputs=pred_output
    )

    # æ–‡æœ¬å›è½¦å‘é€
    msg.submit(user, [msg, img_input, chatbot, image_cache], [msg, img_input, chatbot, image_cache]).then(
        chat, [chatbot, model_id, image_cache], chatbot
    )
    # æŒ‰é’®å‘é€
    send_btn.click(user, [msg, img_input, chatbot, image_cache], [msg, img_input, chatbot, image_cache]).then(
        chat, [chatbot, model_id, image_cache], chatbot
    )


def setup_frpc():
    """è‡ªåŠ¨é…ç½® frpcï¼ˆä»é¡¹ç›® bin ç›®å½•å¤åˆ¶åˆ° Gradio ç¼“å­˜ï¼‰"""
    import shutil
    from pathlib import Path
    
    # é¡¹ç›® bin ç›®å½•ä¸­çš„ frpc
    project_root = Path(__file__).parent.parent
    src_frpc = project_root / "bin" / "frpc_linux_amd64_v0.3"
    
    # Gradio ç¼“å­˜ç›®å½•
    gradio_cache = Path.home() / ".cache" / "huggingface" / "gradio" / "frpc"
    dst_frpc = gradio_cache / "frpc_linux_amd64_v0.3"
    
    if src_frpc.exists():
        gradio_cache.mkdir(parents=True, exist_ok=True)
        if not dst_frpc.exists() or dst_frpc.stat().st_size != src_frpc.stat().st_size:
            shutil.copy2(src_frpc, dst_frpc)
            dst_frpc.chmod(0o755)
            print(f"âœ… frpc å·²é…ç½®: {dst_frpc}")
        return True
    return False


if __name__ == "__main__":
    import sys
    
    PORT = 7860
    
    # æ£€æŸ¥å¯åŠ¨æ¨¡å¼
    use_ngrok = "--ngrok" in sys.argv
    use_share = "--share" in sys.argv
    
    # å¦‚æœä½¿ç”¨ shareï¼Œè‡ªåŠ¨é…ç½® frpc
    if use_share:
        setup_frpc()
    
    print("=" * 50)
    print("ğŸ¥ æ™ºèƒ½åŒ»ç–—ç³»ç»Ÿå¯åŠ¨ä¸­...")
    print("=" * 50)
    
    public_url = None
    
    # ä½¿ç”¨ ngrok è¿›è¡Œå…¬ç½‘éƒ¨ç½²
    if use_ngrok:
        try:
            from pyngrok import ngrok
            # å¦‚æœæœ‰ authtokenï¼Œå¯ä»¥è®¾ç½®: ngrok.set_auth_token("YOUR_TOKEN")
            public_url = ngrok.connect(PORT, "http")
            print(f"âœ… Ngrok å…¬ç½‘é“¾æ¥: {public_url}")
        except Exception as e:
            print(f"âŒ Ngrok å¯åŠ¨å¤±è´¥: {e}")
            print("æç¤º: å¯ä»¥åœ¨ https://ngrok.com æ³¨å†Œè·å–å…è´¹ token")
    
    print(f"ğŸ“ æœ¬åœ°è®¿é—®: http://localhost:{PORT}")
    print(f"ğŸ“ å±€åŸŸç½‘: http://0.0.0.0:{PORT}")
    print("=" * 50)
    print("å¯åŠ¨å‚æ•°:")
    print("  --ngrok  ä½¿ç”¨ ngrok åˆ›å»ºå…¬ç½‘é“¾æ¥")
    print("  --share  ä½¿ç”¨ Gradio å†…ç½®åˆ†äº«(éœ€ç½‘ç»œæ”¯æŒ)")
    print("=" * 50)
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=PORT,
        share=use_share,
        show_error=True,
    )