import gradio as gr
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, recall_score, f1_score
from utils import load_data, chat, load_config
from utils.data_process import DataProcessor
from models.svm import SVM
from models.logistic_regression import LogisticRegression
from models.random_forest import RandomForest
from plot import Visualizer  # å¯¼å…¥å¯è§†åŒ–ç±»


# å…¨å±€å˜é‡å­˜å‚¨æ¨¡å‹å’Œæ•°æ®å¤„ç†å™¨
global_model = None
global_processor = None


# ==================== æ•°æ®é¢„å¤„ç†å‡½æ•° ====================

def load_preview_data(file):
    """åŠ è½½æ•°æ®å¹¶é¢„è§ˆ"""
    if file is None:
        return None, "è¯·å…ˆä¸Šä¼ æ–‡ä»¶"
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        info = f"æ•°æ®å½¢çŠ¶: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—\n"
        info += f"ç¼ºå¤±å€¼æ€»æ•°: {df.isnull().sum().sum()}"
        return df.head(20), info
    except Exception as e:
        return None, f"åŠ è½½å¤±è´¥: {str(e)}"


def analyze_data(file):
    """ä¸Šä¼ æ•°æ®åè‡ªåŠ¨åˆ†æï¼ˆä¸æ‰§è¡Œé¢„å¤„ç†ï¼‰"""
    global global_processor, global_report
    import os
    
    if file is None:
        return "", "", None, None, None, None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        processor = DataProcessor(df)
        global_processor = processor
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs("output/plots", exist_ok=True)
        
        # ç”Ÿæˆå››å¼ åˆ†æå›¾å¹¶ä¿å­˜
        plot_paths = {}
        
        try:
            missing_fig = processor.plot_missing_matrix()
            missing_fig.savefig("output/plots/missing.png", dpi=100, bbox_inches='tight')
            plot_paths['missing'] = "output/plots/missing.png"
        except:
            missing_fig = None
            plot_paths['missing'] = None
        
        try:
            outlier_fig = processor.plot_boxplot(normalize=True)
            outlier_fig.savefig("output/plots/outlier.png", dpi=100, bbox_inches='tight')
            plot_paths['outlier'] = "output/plots/outlier.png"
        except:
            outlier_fig = None
            plot_paths['outlier'] = None
        
        try:
            dist_fig = processor.plot_distribution()
            dist_fig.savefig("output/plots/distribution.png", dpi=100, bbox_inches='tight')
            plot_paths['distribution'] = "output/plots/distribution.png"
        except:
            dist_fig = None
            plot_paths['distribution'] = None
        
        try:
            corr_fig = processor.plot_correlation_heatmap()
            corr_fig.savefig("output/plots/correlation.png", dpi=100, bbox_inches='tight')
            plot_paths['correlation'] = "output/plots/correlation.png"
        except:
            corr_fig = None
            plot_paths['correlation'] = None
        
        # ç”ŸæˆæŠ¥å‘Šï¼ˆå¸¦å›¾ç‰‡è·¯å¾„ï¼‰
        report = processor.generate_report()
        report['plot_paths'] = plot_paths
        global_report = report
        
        # ç”Ÿæˆå¸¦å›¾ç‰‡çš„ Markdown æŠ¥å‘Š
        md_with_images = generate_markdown_with_images(report, plot_paths)
        report['markdown_with_images'] = md_with_images
        
        return (
            md_with_images,
            report['llm_prompt'],
            missing_fig,
            outlier_fig,
            dist_fig,
            corr_fig
        )
    except Exception as e:
        import traceback
        traceback.print_exc()
        return f"åˆ†æå¤±è´¥: {str(e)}", "", None, None, None, None


def generate_markdown_with_images(report: dict, plot_paths: dict) -> str:
    """ç”Ÿæˆå¸¦å›¾ç‰‡çš„ Markdown æŠ¥å‘Š"""
    md = report['markdown']
    
    # åœ¨æŠ¥å‘Šæœ«å°¾æ·»åŠ å›¾ç‰‡éƒ¨åˆ†
    md += "\n\n## ğŸ“ˆ åˆ†æå›¾è¡¨\n\n"
    
    if plot_paths.get('missing'):
        md += "### ç¼ºå¤±å€¼åˆ†æ\n"
        md += f"![ç¼ºå¤±å€¼åˆ†æ](plots/missing.png)\n\n"
    
    if plot_paths.get('outlier'):
        md += "### å¼‚å¸¸å€¼åˆ†æ\n"
        md += f"![å¼‚å¸¸å€¼åˆ†æ](plots/outlier.png)\n\n"
    
    if plot_paths.get('distribution'):
        md += "### æ•°æ®åˆ†å¸ƒ\n"
        md += f"![æ•°æ®åˆ†å¸ƒ](plots/distribution.png)\n\n"
    
    if plot_paths.get('correlation'):
        md += "### ç›¸å…³æ€§åˆ†æ\n"
        md += f"![ç›¸å…³æ€§åˆ†æ](plots/correlation.png)\n\n"
    
    return md


def get_missing_info(file):
    """è·å–ç¼ºå¤±å€¼ä¿¡æ¯"""
    if file is None:
        return None, None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        processor = DataProcessor(df)
        missing_info = processor.get_missing_info()
        missing_fig = processor.plot_missing_matrix()
        
        return missing_info, missing_fig
    except Exception as e:
        return None, None


def get_outlier_info(file):
    """è·å–å¼‚å¸¸å€¼ä¿¡æ¯å¹¶ç»˜åˆ¶ç®±çº¿å›¾"""
    if file is None:
        return None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        processor = DataProcessor(df)
        fig = processor.plot_boxplot()
        return fig
    except Exception as e:
        return None


def get_distribution_info(file):
    """è·å–æ•°æ®åˆ†å¸ƒä¿¡æ¯"""
    if file is None:
        return None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        processor = DataProcessor(df)
        fig = processor.plot_distribution()
        return fig
    except Exception as e:
        return None


def get_correlation_info(file):
    """è·å–ç›¸å…³æ€§çƒ­åŠ›å›¾"""
    if file is None:
        return None, None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        processor = DataProcessor(df)
        fig = processor.plot_correlation_heatmap()
        high_corr = processor.get_high_correlation_pairs()
        
        return fig, high_corr
    except Exception as e:
        return None, None


def process_data(file, fill_strategy, outlier_method):
    """æ‰§è¡Œæ•°æ®é¢„å¤„ç†å¹¶é‡æ–°ç”Ÿæˆåˆ†æå›¾è¡¨"""
    global global_processor, global_report
    import os
    
    if file is None:
        return None, "è¯·å…ˆä¸Šä¼ æ–‡ä»¶", "", "", None, None, None, None
    
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file.name)
        else:
            df = pd.read_excel(file.name)
        
        # æ‰§è¡Œæ•°æ®å¤„ç†
        processor = DataProcessor(df)
        processor.fill_missing(strategy=fill_strategy)
        processor.handle_outliers(method=outlier_method)
        
        global_processor = processor
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs("output/plots", exist_ok=True)
        
        # ç”¨å¤„ç†åçš„æ•°æ®ç”Ÿæˆåˆ†æå›¾è¡¨
        plot_paths = {}
        
        try:
            missing_fig = processor.plot_missing_matrix()
            missing_fig.savefig("output/plots/missing.png", dpi=100, bbox_inches='tight')
            plot_paths['missing'] = "output/plots/missing.png"
        except:
            missing_fig = None
            plot_paths['missing'] = None
        
        try:
            outlier_fig = processor.plot_boxplot(normalize=True)
            outlier_fig.savefig("output/plots/outlier.png", dpi=100, bbox_inches='tight')
            plot_paths['outlier'] = "output/plots/outlier.png"
        except:
            outlier_fig = None
            plot_paths['outlier'] = None
        
        try:
            dist_fig = processor.plot_distribution()
            dist_fig.savefig("output/plots/distribution.png", dpi=100, bbox_inches='tight')
            plot_paths['distribution'] = "output/plots/distribution.png"
        except:
            dist_fig = None
            plot_paths['distribution'] = None
        
        try:
            corr_fig = processor.plot_correlation_heatmap()
            corr_fig.savefig("output/plots/correlation.png", dpi=100, bbox_inches='tight')
            plot_paths['correlation'] = "output/plots/correlation.png"
        except:
            corr_fig = None
            plot_paths['correlation'] = None
        
        # ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š
        report = processor.generate_report()
        report['plot_paths'] = plot_paths
        
        # ç”Ÿæˆå¸¦å›¾ç‰‡çš„ Markdown æŠ¥å‘Š
        md_with_images = generate_markdown_with_images(report, plot_paths)
        report['markdown_with_images'] = md_with_images
        global_report = report
        
        # ç®€çŸ­å¤„ç†æ—¥å¿—
        log = processor.get_processing_log()
        brief_report = f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼\n\nå¤„ç†æ­¥éª¤:\n"
        brief_report += "\n".join([f"â€¢ {item}" for item in log])
        brief_report += f"\n\nå¤„ç†åæ•°æ®: {processor.get_data().shape[0]} è¡Œ Ã— {processor.get_data().shape[1]} åˆ—"
        
        return (
            processor.get_data().head(20), 
            brief_report, 
            md_with_images,
            report['llm_prompt'],
            missing_fig,
            outlier_fig,
            dist_fig,
            corr_fig
        )
    except Exception as e:
        import traceback
        traceback.print_exc()
        return None, f"å¤„ç†å¤±è´¥: {str(e)}", "", "", None, None, None, None


# å…¨å±€æŠ¥å‘Šå­˜å‚¨
global_report = None


def download_report():
    """ä¸‹è½½åˆ†ææŠ¥å‘Šï¼ˆåŒ…å«å›¾ç‰‡çš„ zip åŒ…ï¼‰"""
    global global_report
    import zipfile
    import shutil
    
    if global_report is None:
        return gr.File(visible=False)
    
    import os
    os.makedirs("output", exist_ok=True)
    
    # å†™å…¥å¸¦å›¾ç‰‡è·¯å¾„çš„ Markdown
    md_content = global_report.get('markdown_with_images', global_report['markdown'])
    md_path = "output/data_analysis_report.md"
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(md_content)
    
    # åˆ›å»º zip åŒ…ï¼ˆåŒ…å«æŠ¥å‘Šå’Œå›¾ç‰‡ï¼‰
    zip_path = "output/data_analysis_report.zip"
    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        # æ·»åŠ  Markdown æŠ¥å‘Š
        zipf.write(md_path, "data_analysis_report.md")
        
        # æ·»åŠ å›¾ç‰‡
        plots_dir = "output/plots"
        if os.path.exists(plots_dir):
            for img_file in os.listdir(plots_dir):
                if img_file.endswith('.png'):
                    zipf.write(os.path.join(plots_dir, img_file), f"plots/{img_file}")
    
    return gr.File(value=zip_path, visible=True)


def prepare_for_llm(llm_prompt):
    """å‡†å¤‡å‘é€ç»™ LLM çš„å†…å®¹ï¼Œå¡«å…¥è¾“å…¥æ¡†ä¾›ç”¨æˆ·ç¡®è®¤"""
    global global_report
    import os
    
    if not llm_prompt:
        return "âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®æˆ–æ‰§è¡Œé¢„å¤„ç†ä»¥ç”Ÿæˆåˆ†ææŠ¥å‘Š", None
    
    # å‡†å¤‡å›¾ç‰‡è·¯å¾„ï¼ˆåˆå¹¶æˆä¸€å¼ æ‹¼æ¥å›¾ï¼‰
    image_path = None
    if global_report and global_report.get('plot_paths'):
        # å°è¯•æ‹¼æ¥å››å¼ å›¾ä¸ºä¸€å¼ 
        try:
            from PIL import Image
            
            plot_paths = global_report['plot_paths']
            images = []
            for key in ['missing', 'outlier', 'distribution', 'correlation']:
                path = plot_paths.get(key)
                if path and os.path.exists(path):
                    images.append(Image.open(path))
            
            if images:
                # åˆ›å»º 2x2 æ‹¼æ¥å›¾
                widths = [img.width for img in images]
                heights = [img.height for img in images]
                max_w = max(widths) if widths else 400
                max_h = max(heights) if heights else 300
                
                # åˆ›å»ºç”»å¸ƒ
                combined = Image.new('RGB', (max_w * 2, max_h * 2), 'white')
                
                positions = [(0, 0), (max_w, 0), (0, max_h), (max_w, max_h)]
                for i, img in enumerate(images[:4]):
                    # è°ƒæ•´å›¾ç‰‡å¤§å°
                    img_resized = img.resize((max_w, max_h), Image.Resampling.LANCZOS)
                    combined.paste(img_resized, positions[i])
                
                # ä¿å­˜æ‹¼æ¥å›¾
                os.makedirs("output/plots", exist_ok=True)
                image_path = "output/plots/combined_analysis.png"
                combined.save(image_path)
        except Exception as e:
            print(f"å›¾ç‰‡æ‹¼æ¥å¤±è´¥: {e}")
            # å¦‚æœæ‹¼æ¥å¤±è´¥ï¼Œä½¿ç”¨ç¬¬ä¸€å¼ å›¾
            for key in ['correlation', 'distribution', 'outlier', 'missing']:
                path = global_report.get('plot_paths', {}).get(key)
                if path and os.path.exists(path):
                    image_path = path
                    break
    
    # è¿”å›æ–‡æœ¬å’Œå›¾ç‰‡è·¯å¾„ï¼Œå¡«å…¥è¾“å…¥æ¡†
    text = f"ğŸ“Š æ•°æ®åˆ†æè¯·æ±‚:\n\n{llm_prompt}"
    return text, image_path


def download_chat_history(history):
    """ä¸‹è½½å¯¹è¯å†å²"""
    import os
    import json
    from datetime import datetime
    
    if not history:
        return gr.File(visible=False)
    
    os.makedirs("output", exist_ok=True)
    
    # ç”Ÿæˆ Markdown æ ¼å¼çš„å¯¹è¯è®°å½•
    md_content = "# ğŸ’¬ AI å¯¹è¯è®°å½•\n\n"
    md_content += f"**å¯¼å‡ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
    md_content += "---\n\n"
    
    for msg in history:
        role = msg.get('role', 'unknown')
        content = msg.get('content', '')
        
        if role == 'user':
            md_content += f"### ğŸ‘¤ ç”¨æˆ·\n\n{content}\n\n"
        elif role == 'assistant':
            md_content += f"### ğŸ¤– AI åŠ©æ‰‹\n\n{content}\n\n"
        
        md_content += "---\n\n"
    
    # ä¿å­˜ Markdown æ–‡ä»¶
    output_path = "output/chat_history.md"
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(md_content)
    
    # åŒæ—¶ä¿å­˜ JSON æ ¼å¼ï¼ˆä¾¿äºç¨‹åºè¯»å–ï¼‰
    json_path = "output/chat_history.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(history, f, ensure_ascii=False, indent=2)
    
    return gr.File(value=output_path, visible=True)


def download_processed_data():
    """ä¸‹è½½å¤„ç†åçš„æ•°æ®"""
    global global_processor
    
    if global_processor is None:
        return gr.File(visible=False)
    
    import os
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs("output", exist_ok=True)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    output_path = "output/processed_data.csv"
    global_processor.get_data().to_csv(output_path, index=False)
    return gr.File(value=output_path, visible=True)

# æ¨¡å‹è®­ç»ƒå‡½æ•°ï¼ˆä½¿ç”¨è‡ªå®šä¹‰SVMï¼‰
def train_model(
    file, 
    model_type,
    # éšæœºæ£®æ—å‚æ•°
    rf_n_estimators=100,
    rf_max_depth=None,
    rf_max_features="sqrt",
    # SVMå‚æ•°
    svm_kernel="linear",
    svm_C=1.0,
    svm_gamma="scale",
    # é€»è¾‘å›å½’å‚æ•° 
    lr_penalty="l2",
    lr_C=1.0,
    lr_solver="lbfgs"
):
    global global_model
    try:
        X, y = load_data(file.name)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        if model_type == "Random Forest":
            model = RandomForest(
                n_estimators=rf_n_estimators,
                max_depth=rf_max_depth if rf_max_depth > 0 else None,
                max_features=rf_max_features
            )
        elif model_type == "SVM":
            model = SVM(
                kernel=svm_kernel,
                C=svm_C,
                gamma=svm_gamma
            )
        elif model_type == "Logistic Regression":
            model = LogisticRegression(
                penalty=lr_penalty,
                C=lr_C,
                solver=lr_solver
            )
            
        model.train(X_train, y_train)
        
        preds = model.predict(X_test)
        acc = accuracy_score(y_test, preds)
        rec = recall_score(y_test, preds, average='macro')
        f1 = f1_score(y_test, preds, average='macro')
        
        global_model = model
        
        return f"è®­ç»ƒå®Œæˆï¼\nå‡†ç¡®ç‡: {acc:.3f}\nå¬å›ç‡: {rec:.3f}\nF1åˆ†æ•°: {f1:.3f}"
    
    except Exception as e:
        return f"è®­ç»ƒå‡ºé”™: {str(e)}"

# é¢„æµ‹å‡½æ•°
def make_prediction(pred_file):
    if global_model is None:
        return "âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼"
    
    try:
        X_pred, _ = load_data(pred_file.name)
        predictions = global_model.predict(X_pred)
        
        return pd.DataFrame({
            'æ ·æœ¬åºå·': range(1, len(predictions)+1),
            'é¢„æµ‹ç»“æœ': predictions
        })
    
    except Exception as e:
        return f"é¢„æµ‹å‡ºé”™: {str(e)}"
    
def evaluate_model(file):
    if global_model is None:
        return "âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹ï¼"
    if not file:
        return "âš ï¸ è¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼"
    # try:

    X, y = load_data(file.name)
    df = pd.DataFrame(X)
    df['æ ‡ç­¾'] = y
    # æå–ç±»åˆ«
    classes = df['æ ‡ç­¾'].unique()
    viz = Visualizer(classes)
    y_proba = global_model.predict_proba(X)
    roc_fig = viz.plot_roc(y, y_proba)
    pr_fig = viz.plot_pr(y, y_proba)
    metrics = global_model.evaluate(X, y)
    confusion_matrix_fig = viz.plot_confusion_matrix(metrics['confusion_matrix'])
    return df, roc_fig, pr_fig, confusion_matrix_fig

                # åŠ¨æ€æ˜¾ç¤ºå‚æ•°åŒºçš„å›è°ƒå‡½æ•°
def toggle_params(model_type):
    return {
        rf_params: gr.Accordion(visible=model_type == "Random Forest"),
        svm_params: gr.Accordion(visible=model_type == "SVM"),
        lr_params: gr.Accordion(visible=model_type == "Logistic Regression")
    }     
        
# ç•Œé¢å¸ƒå±€
with gr.Blocks() as demo:
    gr.Markdown("# StarshotğŸŒŸ")
    
    with gr.Row():
        # å·¦ä¾§é¢æ¿
        with gr.Column(scale=2):
            with gr.Tab("æ•°æ®å¤„ç†"):
                with gr.Row():
                    data_file = gr.File(
                        label="ä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼ˆCSV/XLSXï¼‰",
                        file_types=[".csv", ".xlsx"]
                    )
                    data_info = gr.Textbox(label="æ•°æ®ä¿¡æ¯", lines=2)
                
                data_output = gr.DataFrame(label="æ•°æ®é¢„è§ˆ", interactive=False)
                
                with gr.Accordion("æ•°æ®åˆ†æ", open=False):
                    with gr.Tab("ç¼ºå¤±å€¼åˆ†æ"):
                        missing_btn = gr.Button("åˆ†æç¼ºå¤±å€¼", size="sm")
                        missing_info = gr.DataFrame(label="ç¼ºå¤±å€¼ç»Ÿè®¡")
                        missing_plot = gr.Plot(label="ç¼ºå¤±å€¼çŸ©é˜µå›¾")
                    
                    with gr.Tab("å¼‚å¸¸å€¼åˆ†æ"):
                        outlier_btn = gr.Button("åˆ†æå¼‚å¸¸å€¼", size="sm")
                        outlier_plot = gr.Plot(label="ç®±çº¿å›¾")
                    
                    with gr.Tab("æ•°æ®åˆ†å¸ƒ"):
                        dist_btn = gr.Button("åˆ†æåˆ†å¸ƒ", size="sm")
                        dist_plot = gr.Plot(label="åˆ†å¸ƒå›¾")
                    
                    with gr.Tab("ç›¸å…³æ€§åˆ†æ"):
                        corr_btn = gr.Button("åˆ†æç›¸å…³æ€§", size="sm")
                        corr_plot = gr.Plot(label="ç›¸å…³æ€§çƒ­åŠ›å›¾")
                        high_corr_df = gr.DataFrame(label="é«˜ç›¸å…³ç‰¹å¾å¯¹ (|r| > 0.8)")
                
                gr.Markdown("### æ•°æ®é¢„å¤„ç†")
                with gr.Row():
                    fill_strategy = gr.Dropdown(
                        choices=["auto", "median", "mean", "mode", "knn", "drop"],
                        value="auto",
                        label="ç¼ºå¤±å€¼å¤„ç†ç­–ç•¥"
                    )
                    outlier_method = gr.Dropdown(
                        choices=["cap", "drop", "median"],
                        value="cap",
                        label="å¼‚å¸¸å€¼å¤„ç†æ–¹æ³•"
                    )
                
                preprocess_btn = gr.Button("æ‰§è¡Œé¢„å¤„ç†", variant="primary")
                preprocess_output = gr.Textbox(label="å¤„ç†æ—¥å¿—", lines=4)
                
                with gr.Accordion("ğŸ“Š æ•°æ®åˆ†ææŠ¥å‘Š", open=True):
                    with gr.Row():
                        download_data_btn = gr.Button("ğŸ“¥ ä¸‹è½½æ•°æ®", variant="secondary", size="sm")
                        download_report_btn = gr.Button("ğŸ“„ ä¸‹è½½æŠ¥å‘Š", variant="secondary", size="sm")
                        send_to_llm_btn = gr.Button("ğŸ¤– å‘é€ç»™AIåˆ†æ", variant="primary", size="sm")
                    
                    with gr.Row():
                        processed_file = gr.File(label="å¤„ç†åæ•°æ®", visible=False)
                        report_file = gr.File(label="åˆ†ææŠ¥å‘Š", visible=False)
                    
                    # å››å¼ åˆ†æå›¾è¡¨
                    with gr.Row():
                        with gr.Column():
                            auto_missing_plot = gr.Plot(label="ç¼ºå¤±å€¼åˆ†æ")
                        with gr.Column():
                            auto_outlier_plot = gr.Plot(label="å¼‚å¸¸å€¼åˆ†æ")
                    
                    with gr.Row():
                        with gr.Column():
                            auto_dist_plot = gr.Plot(label="æ•°æ®åˆ†å¸ƒ")
                        with gr.Column():
                            auto_corr_plot = gr.Plot(label="ç›¸å…³æ€§åˆ†æ")
                    
                    # æ–‡å­—æŠ¥å‘Š
                    with gr.Accordion("ğŸ“ è¯¦ç»†æŠ¥å‘Š", open=False):
                        report_markdown = gr.Markdown(label="åˆ†ææŠ¥å‘Š", value="*æ‰§è¡Œé¢„å¤„ç†åè‡ªåŠ¨ç”ŸæˆæŠ¥å‘Š*")
                    
                    llm_prompt_state = gr.State(value="")
            with gr.Tab("æ¨¡å‹è®­ç»ƒ"):
                train_file = gr.File(
                    label="ä¸Šä¼ è®­ç»ƒæ–‡ä»¶ï¼ˆCSV/XLSXï¼‰",
                    file_types=[".csv", ".xlsx"]
                )
                model_choice = gr.Dropdown(
                    choices=["Random Forest", "SVM", "Logistic Regression"],
                    label="é€‰æ‹©æ¨¡å‹",
                    value="Random Forest"
                )
                # å„æ¨¡å‹å‚æ•°åŒº
                with gr.Accordion("éšæœºæ£®æ—å‚æ•°", visible=True) as rf_params:  # é»˜è®¤æ˜¾ç¤º
                    rf_n_estimators = gr.Slider(50, 500, value=100, step=50, label="æ ‘çš„æ•°é‡ (n_estimators)")
                    rf_max_depth = gr.Slider(2, 50, value=None, step=1, label="æœ€å¤§æ·±åº¦ (max_depth)")
                    rf_max_features = gr.Dropdown(
                        ["sqrt", "log2", 0.5, 0.8], 
                        value="sqrt", 
                        label="æœ€å¤§ç‰¹å¾æ•° (max_features)"
                    )
                
                with gr.Accordion("SVMå‚æ•°", visible=False) as svm_params:
                    svm_kernel = gr.Dropdown(
                        ["linear", "poly", "rbf", "sigmoid"],
                        value="linear",
                        label="æ ¸å‡½æ•° (kernel)"
                    )
                    svm_C = gr.Slider(0.1, 10.0, value=1.0, step=0.1, label="æ­£åˆ™åŒ–å¼ºåº¦ (C)")
                    svm_gamma = gr.Dropdown(
                        ["scale", "auto"],
                        value="scale",
                        label="æ ¸ç³»æ•° (gamma)"
                    )
                
                with gr.Accordion("é€»è¾‘å›å½’å‚æ•°", visible=False) as lr_params:
                    lr_penalty = gr.Dropdown(
                        ["l2", "l1", "elasticnet", "none"],
                        value="l2",
                        label="æ­£åˆ™åŒ–ç±»å‹ (penalty)"
                    )
                    lr_C = gr.Slider(0.01, 10.0, value=1.0, step=0.1, label="æ­£åˆ™åŒ–å¼ºåº¦ (C)")
                    lr_solver = gr.Dropdown(
                        ["lbfgs", "sag", "saga", "newton-cg", "liblinear"],
                        value="lbfgs",
                        label="ä¼˜åŒ–ç®—æ³• (solver)"
                    )
   
                model_choice.change(
                    fn=toggle_params,
                    inputs=model_choice,
                    outputs=[rf_params, svm_params, lr_params]
                )
                train_btn = gr.Button("å¼€å§‹è®­ç»ƒ", variant="primary") 
                train_output = gr.Textbox(
                    label="è®­ç»ƒç»“æœ",
                    interactive=False,
                    placeholder="è®­ç»ƒç»“æœå°†æ˜¾ç¤ºåœ¨æ­¤å¤„..."
                )
            with gr.Tab("æ¨¡å‹è¯„ä¼°"):
                # dataframe
                # å››ä¸ªç»˜å›¾åŒº
                # ä¸Šä¼ æ–‡ä»¶
                eval_file = gr.File(
                    label="ä¸Šä¼ è¯„ä¼°æ–‡ä»¶ï¼ˆCSV/XLSXï¼‰",
                    file_types=[".csv", ".xlsx"]
                )
                # å¼€å§‹è¯„ä¼°æŒ‰é’®
                eval_btn = gr.Button("å¼€å§‹è¯„ä¼°", variant="secondary")
                dataframe_component = gr.DataFrame(
                    label="æ¨¡å‹æŒ‡æ ‡",
                )
                roc_curve_plot = gr.Plot(label="ROCæ›²çº¿")
                pr_curve_plot = gr.Plot(label="PRæ›²çº¿")
                confusion_matrix_plot = gr.Plot(label="æ··æ·†çŸ©é˜µ")
                
                
            with gr.Tab("æ‰¹é‡é¢„æµ‹"):
                pred_file = gr.File(
                    label="ä¸Šä¼ é¢„æµ‹æ–‡ä»¶ï¼ˆCSV/XLSXï¼‰",
                    file_types=[".csv", ".xlsx"]
                )
                pred_btn = gr.Button("å¼€å§‹é¢„æµ‹", variant="secondary")
                pred_output = gr.Dataframe(
                    label="é¢„æµ‹ç»“æœ",
                    headers=["æ ·æœ¬åºå·", "é¢„æµ‹ç»“æœ"],
                    interactive=False
                )
                
            with gr.Tab("å¯è§†åŒ–"):
                pass
            #TODO
                

        # å³ä¾§èŠå¤©é¢æ¿
        with gr.Column(scale=1):
            chatbot = gr.Chatbot(
                label="æ™ºèƒ½åŠ©æ‰‹",
                height=400,
                # bubble_full_width=False,
            )
            with gr.Row():
                msg = gr.Textbox(
                    label="è¾“å…¥æ¶ˆæ¯",
                    placeholder="è¾“å…¥é—®é¢˜åæŒ‰å›è½¦å‘é€",
                    max_lines=3,
                    scale=4
                )
                img_input = gr.Image(
                    label="ä¸Šä¼ å›¾ç‰‡",
                    type="filepath",
                    scale=1
                )
            model_id = gr.Dropdown(
                label="åŒ»ç–—æ™ºèƒ½ä½“",
                value="å¥åº·ç®¡ç†",
                choices=["ç–¾ç—…è¯Šæ–­", "å¥åº·ç®¡ç†", "è¥å…»æŒ‡å¯¼"]
            )
            provider_info = gr.Markdown(value="**å½“å‰æ¨¡å‹**: qwen / qwen-max")
            with gr.Row():
                send_btn = gr.Button("å‘é€", variant="primary", size='sm')
                clear_btn = gr.ClearButton([msg, chatbot, img_input], size='sm')
                download_history_btn = gr.Button("ğŸ“¥ å¯¼å‡ºå¯¹è¯", variant="secondary", size='sm')
            chat_history_file = gr.File(label="å¯¹è¯è®°å½•", visible=False)
            
            def update_provider_info(agent_id):
                """æ›´æ–°æ˜¾ç¤ºçš„æä¾›å•†ä¿¡æ¯"""
                try:
                    config = load_config()
                    agent_config = config.get('agent_models', {}).get(agent_id, {})
                    provider = agent_config.get('provider', config.get('default_provider', 'kimi'))
                    model_type = agent_config.get('model', 'default')
                    
                    # è·å–å®é™…æ¨¡å‹åç§°
                    providers = config.get('llm_providers', {})
                    model_name = providers.get(provider, {}).get('models', {}).get(model_type, 'unknown')
                    
                    return f"**å½“å‰æ¨¡å‹**: {provider} / {model_name}"
                except:
                    return "**å½“å‰æ¨¡å‹**: é…ç½®åŠ è½½å¤±è´¥"
            
            model_id.change(
                fn=update_provider_info,
                inputs=model_id,
                outputs=provider_info
            )
            
            # ç”¨äºå­˜å‚¨å›¾ç‰‡è·¯å¾„ï¼Œä¾› API è°ƒç”¨ä½¿ç”¨
            image_cache = gr.State(None)
            
            def user(user_message, image, history, img_cache):
                """å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆæ–‡æœ¬+å›¾ç‰‡ï¼‰"""
                if not user_message and not image:
                    return "", None, history, img_cache
                
                new_history = list(history)
                
                # æ„å»ºæ˜¾ç¤ºæ–‡æœ¬
                if image:
                    text = user_message or "è¯·åˆ†æè¿™å¼ å›¾ç‰‡"
                    display_text = f"ğŸ“· [å·²ä¸Šä¼ å›¾ç‰‡]\n{text}"
                    img_cache = image  # ç¼“å­˜å›¾ç‰‡è·¯å¾„ä¾› API ä½¿ç”¨
                else:
                    display_text = user_message
                    img_cache = None
                
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆçº¯æ–‡æœ¬æ ¼å¼ï¼ŒGradio å…¼å®¹ï¼‰
                new_history.append({"role": "user", "content": display_text})
                    
                return "", None, new_history, img_cache

    # ==================== äº‹ä»¶ç»‘å®š ====================
    
    # æ•°æ®å¤„ç†äº‹ä»¶ - ä¸Šä¼ åè‡ªåŠ¨é¢„è§ˆå¹¶åˆ†æ
    data_file.change(
        fn=load_preview_data,
        inputs=data_file,
        outputs=[data_output, data_info]
    ).then(
        fn=analyze_data,
        inputs=data_file,
        outputs=[
            report_markdown,
            llm_prompt_state,
            auto_missing_plot,
            auto_outlier_plot,
            auto_dist_plot,
            auto_corr_plot
        ]
    )
    
    missing_btn.click(
        fn=get_missing_info,
        inputs=data_file,
        outputs=[missing_info, missing_plot]
    )
    
    outlier_btn.click(
        fn=get_outlier_info,
        inputs=data_file,
        outputs=outlier_plot
    )
    
    dist_btn.click(
        fn=get_distribution_info,
        inputs=data_file,
        outputs=dist_plot
    )
    
    corr_btn.click(
        fn=get_correlation_info,
        inputs=data_file,
        outputs=[corr_plot, high_corr_df]
    )
    
    preprocess_btn.click(
        fn=process_data,
        inputs=[data_file, fill_strategy, outlier_method],
        outputs=[
            data_output, 
            preprocess_output, 
            report_markdown, 
            llm_prompt_state,
            auto_missing_plot,
            auto_outlier_plot,
            auto_dist_plot,
            auto_corr_plot
        ]
    )
    
    download_data_btn.click(
        fn=download_processed_data,
        outputs=processed_file
    )
    
    download_report_btn.click(
        fn=download_report,
        outputs=report_file
    )
    
    # å‘é€ç»™ LLM åˆ†æï¼šå¡«å…¥è¾“å…¥æ¡†å’Œå›¾ç‰‡æ¡†ï¼Œè®©ç”¨æˆ·ç¡®è®¤åå‘é€
    send_to_llm_btn.click(
        fn=prepare_for_llm,
        inputs=[llm_prompt_state],
        outputs=[msg, img_input]
    )
    
    # æ¨¡å‹è®­ç»ƒäº‹ä»¶
    train_btn.click(
        fn=train_model,
        inputs=[
            train_file, 
            model_choice,      # æ¨¡å‹ç±»å‹
            # éšæœºæ£®æ—å‚æ•°
            rf_n_estimators, 
            rf_max_depth, 
            rf_max_features,
            # SVMå‚æ•°
            svm_kernel,
            svm_C,
            svm_gamma,
            # é€»è¾‘å›å½’å‚æ•°
            lr_penalty,
            lr_C,
            lr_solver
        ],
        outputs=train_output
    )

    
    eval_btn.click(
        evaluate_model,
        inputs=eval_file,
        outputs=[dataframe_component, roc_curve_plot, pr_curve_plot, confusion_matrix_plot]
    )
    
    pred_btn.click(
        make_prediction,
        inputs=pred_file,
        outputs=pred_output
    )

    # æ–‡æœ¬å›è½¦å‘é€
    msg.submit(user, [msg, img_input, chatbot, image_cache], [msg, img_input, chatbot, image_cache]).then(
        chat, [chatbot, model_id, image_cache], chatbot
    )
    # æŒ‰é’®å‘é€
    send_btn.click(user, [msg, img_input, chatbot, image_cache], [msg, img_input, chatbot, image_cache]).then(
        chat, [chatbot, model_id, image_cache], chatbot
    )
    
    # å¯¼å‡ºå¯¹è¯å†å²
    download_history_btn.click(
        fn=download_chat_history,
        inputs=chatbot,
        outputs=chat_history_file
    )


def setup_frpc():
    """è‡ªåŠ¨é…ç½® frpcï¼ˆä»é¡¹ç›® bin ç›®å½•å¤åˆ¶åˆ° Gradio ç¼“å­˜ï¼‰"""
    import shutil
    from pathlib import Path
    
    # é¡¹ç›® bin ç›®å½•ä¸­çš„ frpc
    project_root = Path(__file__).parent.parent
    src_frpc = project_root / "bin" / "frpc_linux_amd64_v0.3"
    
    # Gradio ç¼“å­˜ç›®å½•
    gradio_cache = Path.home() / ".cache" / "huggingface" / "gradio" / "frpc"
    dst_frpc = gradio_cache / "frpc_linux_amd64_v0.3"
    
    if src_frpc.exists():
        gradio_cache.mkdir(parents=True, exist_ok=True)
        if not dst_frpc.exists() or dst_frpc.stat().st_size != src_frpc.stat().st_size:
            shutil.copy2(src_frpc, dst_frpc)
            dst_frpc.chmod(0o755)
            print(f"âœ… frpc å·²é…ç½®: {dst_frpc}")
        return True
    return False


if __name__ == "__main__":
    import sys
    
    PORT = 7860
    
    # æ£€æŸ¥å¯åŠ¨æ¨¡å¼
    use_ngrok = "--ngrok" in sys.argv
    use_share = "--share" in sys.argv
    
    # å¦‚æœä½¿ç”¨ shareï¼Œè‡ªåŠ¨é…ç½® frpc
    if use_share:
        setup_frpc()
    
    print("=" * 50)
    print("ğŸ¥ æ™ºèƒ½åŒ»ç–—ç³»ç»Ÿå¯åŠ¨ä¸­...")
    print("=" * 50)
    
    public_url = None
    
    # ä½¿ç”¨ ngrok è¿›è¡Œå…¬ç½‘éƒ¨ç½²
    if use_ngrok:
        try:
            from pyngrok import ngrok
            # å¦‚æœæœ‰ authtokenï¼Œå¯ä»¥è®¾ç½®: ngrok.set_auth_token("YOUR_TOKEN")
            public_url = ngrok.connect(PORT, "http")
            print(f"âœ… Ngrok å…¬ç½‘é“¾æ¥: {public_url}")
        except Exception as e:
            print(f"âŒ Ngrok å¯åŠ¨å¤±è´¥: {e}")
            print("æç¤º: å¯ä»¥åœ¨ https://ngrok.com æ³¨å†Œè·å–å…è´¹ token")
    
    print(f"ğŸ“ æœ¬åœ°è®¿é—®: http://localhost:{PORT}")
    print(f"ğŸ“ å±€åŸŸç½‘: http://0.0.0.0:{PORT}")
    print("=" * 50)
    print("å¯åŠ¨å‚æ•°:")
    print("  --ngrok  ä½¿ç”¨ ngrok åˆ›å»ºå…¬ç½‘é“¾æ¥")
    print("  --share  ä½¿ç”¨ Gradio å†…ç½®åˆ†äº«(éœ€ç½‘ç»œæ”¯æŒ)")
    print("=" * 50)
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=PORT,
        share=use_share,
        show_error=True,
    )